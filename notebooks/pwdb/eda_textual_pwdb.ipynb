{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [],
   "source": [
    "import pathlib as path\n",
    "import pandas as pd\n",
    "from collections import Iterable\n",
    "import plotly.express as px\n",
    "import spacy\n",
    "from nltk.corpus import stopwords\n",
    "from collections import  Counter\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from tqdm import tqdm\n",
    "import concurrent.futures"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [],
   "source": [
    "FOLDER  = path.Path(\"/home/jovyan/data/\")\n",
    "\n",
    "SRC_FILE_NAME = \"covid19db.json\"\n",
    "\n",
    "OUTPUT_FILE_NAME = \"eda_pwdb_result.html\"\n",
    "\n",
    "SRC_FILE_PATH = FOLDER / SRC_FILE_NAME\n",
    "\n",
    "OUTPUT_FILE_PATH = FOLDER / OUTPUT_FILE_NAME"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# EDA on categorical data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [],
   "source": [
    "def get_list_from_series(series : pd.Series):\n",
    "    result_list = []\n",
    "    for elements in series:\n",
    "        if type(elements)==list:\n",
    "            for element in elements:\n",
    "               result_list.append(element)\n",
    "    return result_list"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [],
   "source": [
    "def prepare_series_from_dataframe(df : pd.DataFrame):\n",
    "    result_dict = {}\n",
    "    columns = df.columns\n",
    "    for column in columns:\n",
    "        if type(df[column]) == pd.Series:\n",
    "            if type(df[column][0]) == list:\n",
    "                tmp_list = get_list_from_series(df[column])\n",
    "                result_dict[column]=tmp_list\n",
    "    return result_dict"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [],
   "source": [
    "def eda_on_categorical_data(df : pd.DataFrame):\n",
    "    prepared_data = prepare_series_from_dataframe(df)\n",
    "    plots = []\n",
    "    pbar = tqdm(prepared_data.keys())\n",
    "    for key in pbar:\n",
    "        pbar.set_description('Eda on categorical data : ',str(key))\n",
    "        if type(prepared_data[key])!=dict:\n",
    "            try:\n",
    "                duplicate_dict = Counter(prepared_data[key])\n",
    "                duplicate_dict = dict(sorted(duplicate_dict.items(), key=lambda item: item[1],reverse=True))\n",
    "                column_stat = pd.DataFrame({'Data':duplicate_dict.keys(),'Count':duplicate_dict.values()})\n",
    "                plots.append(px.bar(column_stat,x='Data',y='Count',title=key))\n",
    "                plots.append(px.pie(column_stat,names='Data',values='Count',title=key))\n",
    "            except:\n",
    "                print('Some error for categorial data : ',key)\n",
    "    return plots"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# EDA on textual data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [],
   "source": [
    "def get_str_columns(df : pd.DataFrame):\n",
    "    column_names = []\n",
    "    for column in df.columns:\n",
    "        if type(df[column][0]) == str :\n",
    "            column_names.append(column)\n",
    "    return column_names\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [],
   "source": [
    "def plot_sentence_length_histogram(df : pd.DataFrame, title : str):\n",
    "    plots =[]\n",
    "    tmp_df = pd.Series(df.str.len())\n",
    "    plots.append(px.histogram(tmp_df,title='Sentence len for: '+title))\n",
    "    return plots\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [],
   "source": [
    "def plot_top_non_stopwords_barchart(text,title : str):\n",
    "    stop=set(stopwords.words('english'))\n",
    "    new= text.str.split()\n",
    "    new=new.values.tolist()\n",
    "    corpus=[]\n",
    "    plots = []\n",
    "    for element in new:\n",
    "        if isinstance(element,Iterable):\n",
    "            for word in element:\n",
    "                corpus.append(str.lower(word))\n",
    "    counter=Counter(corpus)\n",
    "    most=counter.most_common()\n",
    "    x, y=[], []\n",
    "    for word,count in most[:40]:\n",
    "        if word not in stop:\n",
    "            x.append(word)\n",
    "            y.append(count)\n",
    "\n",
    "    plots.append(px.bar(x=y,y=x,title='Word frec for : '+title))\n",
    "    return plots"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [],
   "source": [
    "def plot_top_ngrams_barchart(text,title : str ,n=2):\n",
    "    plots = []\n",
    "    try:\n",
    "        stop=set(stopwords.words('english'))\n",
    "\n",
    "        new= text.str.split()\n",
    "        new=new.values.tolist()\n",
    "        corpus=[]\n",
    "        for element in new:\n",
    "            if isinstance(element,Iterable):\n",
    "                for word in element:\n",
    "                    corpus.append(str.lower(str(word)))\n",
    "        def _get_top_ngram(corpus_local, n=None):\n",
    "            vec = CountVectorizer(ngram_range=(n, n)).fit(corpus_local)\n",
    "            bag_of_words = vec.transform(corpus_local)\n",
    "            sum_words = bag_of_words.sum(axis=0)\n",
    "            words_freq = [(word, sum_words[0, idx])\n",
    "                          for word, idx in vec.vocabulary_.items()]\n",
    "            words_freq =sorted(words_freq, key = lambda x: x[1], reverse=True)\n",
    "            return words_freq[:10]\n",
    "\n",
    "        top_n_bigrams=_get_top_ngram(corpus,n)[:10]\n",
    "        x,y=map(list,zip(*top_n_bigrams))\n",
    "        plots.append(px.bar(x=y,y=x,title='Top '+str(n)+' grams : '+title))\n",
    "    except:\n",
    "        print(\"Some error for textual data : \",title)\n",
    "    return plots\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [],
   "source": [
    "def plot_named_entity_barchart(text,title:str):\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "    ent = []\n",
    "    plots = []\n",
    "    for row in text:\n",
    "        if type(row) == str:\n",
    "            doc = nlp(row)\n",
    "            for e in doc.ents:\n",
    "                ent.append(e.label_)\n",
    "    if ent:\n",
    "        counter=Counter(ent)\n",
    "        count=counter.most_common()\n",
    "        x,y=map(list,zip(*count))\n",
    "        plots.append(px.bar(x=y,y=x,title='Named entity : '+title))\n",
    "    return plots"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [],
   "source": [
    "def plot_most_common_named_entity_barchart(text,title, entity=\"ORG\"):\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "    ent = []\n",
    "    plots = []\n",
    "    for row in text:\n",
    "        if type(row) == str:\n",
    "            doc = nlp(row)\n",
    "            for e in doc.ents:\n",
    "                if e.label_ == entity:\n",
    "                    ent.append(str.lower(e.text))\n",
    "    if ent:\n",
    "        counter=Counter(ent)\n",
    "        count=counter.most_common(10)\n",
    "        x,y=map(list,zip(*count))\n",
    "        plots.append(px.bar(x=y,y=x,title='Most common named entity ['+entity+'] : '+title))\n",
    "    return plots"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [],
   "source": [
    "def plot_most_common_noun_phrases_barchart(text,title):\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "    ent = []\n",
    "    plots = []\n",
    "    for row in text:\n",
    "        if type(row) == str:\n",
    "            doc = nlp(row)\n",
    "            doc.cats\n",
    "            for noun_phrase in doc.noun_chunks:\n",
    "                    ent.append(str.lower(noun_phrase.text))\n",
    "    if ent:\n",
    "        counter=Counter(ent)\n",
    "        count=counter.most_common(10)\n",
    "        x,y=map(list,zip(*count))\n",
    "        plots.append(px.bar(x=y,y=x,title='Most common noun phrases: '+title))\n",
    "    return plots"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [],
   "source": [
    "def eda_on_text_data(df: pd.DataFrame):\n",
    "    str_column_names = get_str_columns(df)\n",
    "    plots = []\n",
    "    pbar = tqdm(str_column_names)\n",
    "    for column_name in pbar:\n",
    "        pbar.set_description('Eda on text data : ',column_name)\n",
    "        with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "            futures = []\n",
    "            #plot_sentence_length_histogram(df[column_name],column_name)\n",
    "            futures.append(executor.submit(plot_top_non_stopwords_barchart,df[column_name],column_name))\n",
    "            #futures.append(executor.submit(plot_top_ngrams_barchart,df[column_name],column_name,3))\n",
    "            #futures.append(executor.submit(plot_named_entity_barchart,df[column_name],column_name))\n",
    "            #futures.append(executor.submit(plot_most_common_named_entity_barchart,df[column_name],column_name,'ORG'))\n",
    "            #futures.append(executor.submit(plot_most_common_noun_phrases_barchart,df[column_name],column_name))\n",
    "            for future in concurrent.futures.as_completed(futures):\n",
    "                plots+=future.result()\n",
    "    return plots"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [],
   "source": [
    "def execute_eda(src_path : path.PosixPath, output_path:path.PosixPath):\n",
    "    if src_path.exists():\n",
    "        df = pd.read_json(src_path)\n",
    "        specific_categorical_columns= ['country', 'category', 'subcategory',\n",
    "        'actors', 'target_groups', 'funding','sectors']\n",
    "        specific_textual_columns= ['title',\n",
    "       'background_info_description', 'content_of_measure_description',\n",
    "        'use_of_measure_description','involvement_of_social_partners_description']\n",
    "        plots = []\n",
    "        with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "            futures = [executor.submit(eda_on_categorical_data,df[specific_categorical_columns]),\n",
    "                       executor.submit(eda_on_text_data,df[specific_textual_columns])]\n",
    "            for future in concurrent.futures.as_completed(futures):\n",
    "                plots+=future.result()\n",
    "        pbar = tqdm(plots)\n",
    "        if output_path is not None:\n",
    "            if output_path.exists():\n",
    "                with open(output_path,'w') as f:\n",
    "                    pbar.set_description('Generate HTML report.')\n",
    "                    for plot in pbar:\n",
    "                        f.write(plot.to_html(full_html=False,include_plotlyjs='cdn'))\n",
    "            else:\n",
    "                print('This output_path:',output_path,'is invalid!')\n",
    "        else:\n",
    "             pbar.set_description('Render plots in jupyter notebook.')\n",
    "             for plot in pbar:\n",
    "                plot.show()\n",
    "    else:\n",
    "        print('This src_path:',src_path,'is invalid!')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [],
   "source": [
    "class EdaPWDB():\n",
    "    def __init__(self, src_path : path.PosixPath):\n",
    "        if src_path.exists():\n",
    "            self.plots = []\n",
    "            self.df = pd.read_json(src_path)\n",
    "            self.df ['title', 'country', 'category', 'subcategory',\n",
    "       'background_info_description', 'content_of_measure_description',\n",
    "        'use_of_measure_description','involvement_of_social_partners_description',\n",
    "        'actors', 'target_groups', 'funding'].head(1)\n",
    "        else:\n",
    "            print('This src_path:',src_path,'is invalid!')\n",
    "    def execute(self):\n",
    "        specific_categorical_columns= ['country', 'category', 'subcategory',\n",
    "        'actors', 'target_groups', 'funding']\n",
    "        specific_textual_columns= ['title',\n",
    "       'background_info_description', 'content_of_measure_description',\n",
    "        'use_of_measure_description','involvement_of_social_partners_description']\n",
    "        self.df[specific_textual_columns].head(1)\n",
    "        with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "            futures = [executor.submit(eda_on_categorical_data,self.df[specific_categorical_columns]),\n",
    "                       executor.submit(eda_on_text_data,self.df[specific_textual_columns])]\n",
    "            for future in concurrent.futures.as_completed(futures):\n",
    "                self.plots+=future.result()\n",
    "    def show(self):\n",
    "        progress_bar = tqdm(self.plots)\n",
    "        progress_bar.set_description('Render plots in jupyter notebook.')\n",
    "        for plot in progress_bar:\n",
    "            plot.show()\n",
    "    def export_to_html(self,output_path : path.PosixPath):\n",
    "        progress_bar = tqdm(self.plots)\n",
    "        with open(output_path,'w') as f:\n",
    "            progress_bar.set_description('Generate HTML report.')\n",
    "            for plot in progress_bar:\n",
    "               f.write(plot.to_html(full_html=False,include_plotlyjs='cdn'))\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [],
   "source": [
    "#execute_eda(SRC_FILE_PATH,None)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [],
   "source": [
    "eda_pwdb = EdaPWDB(SRC_FILE_PATH)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Eda on categorical data : :   0%|          | 0/3 [00:00<?, ?it/s]\n",
      "  0%|          | 0/8 [00:00<?, ?it/s]\u001B[A\n",
      "Eda on text data : :   0%|          | 0/8 [00:00<?, ?it/s]\u001B[A\n",
      "Eda on categorical data : : 100%|██████████| 3/3 [00:00<00:00,  9.30it/s]\n"
     ]
    },
    {
     "ename": "LookupError",
     "evalue": "\n**********************************************************************\n  Resource \u001B[93mstopwords\u001B[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001B[31m>>> import nltk\n  >>> nltk.download('stopwords')\n  \u001B[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001B[93mcorpora/stopwords\u001B[0m\n\n  Searched in:\n    - '/home/jovyan/nltk_data'\n    - '/opt/conda/nltk_data'\n    - '/opt/conda/share/nltk_data'\n    - '/opt/conda/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n**********************************************************************\n",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mLookupError\u001B[0m                               Traceback (most recent call last)",
      "\u001B[0;32m/opt/conda/lib/python3.8/site-packages/nltk/corpus/util.py\u001B[0m in \u001B[0;36m__load\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m     82\u001B[0m                 \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 83\u001B[0;31m                     \u001B[0mroot\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mnltk\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdata\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfind\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"{}/{}\"\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mformat\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msubdir\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mzip_name\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     84\u001B[0m                 \u001B[0;32mexcept\u001B[0m \u001B[0mLookupError\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/opt/conda/lib/python3.8/site-packages/nltk/data.py\u001B[0m in \u001B[0;36mfind\u001B[0;34m(resource_name, paths)\u001B[0m\n\u001B[1;32m    584\u001B[0m     \u001B[0mresource_not_found\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m\"\\n%s\\n%s\\n%s\\n\"\u001B[0m \u001B[0;34m%\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0msep\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmsg\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0msep\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 585\u001B[0;31m     \u001B[0;32mraise\u001B[0m \u001B[0mLookupError\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mresource_not_found\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    586\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mLookupError\u001B[0m: \n**********************************************************************\n  Resource \u001B[93mstopwords\u001B[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001B[31m>>> import nltk\n  >>> nltk.download('stopwords')\n  \u001B[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001B[93mcorpora/stopwords.zip/stopwords/\u001B[0m\n\n  Searched in:\n    - '/home/jovyan/nltk_data'\n    - '/opt/conda/nltk_data'\n    - '/opt/conda/share/nltk_data'\n    - '/opt/conda/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n**********************************************************************\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[0;31mLookupError\u001B[0m                               Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-58-e7df4d4afc8c>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0meda_pwdb\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mexecute\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      2\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m<ipython-input-52-af27d78b911a>\u001B[0m in \u001B[0;36mexecute\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m     17\u001B[0m                        executor.submit(eda_on_text_data,self.df[specific_textual_columns])]\n\u001B[1;32m     18\u001B[0m             \u001B[0;32mfor\u001B[0m \u001B[0mfuture\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mconcurrent\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfutures\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mas_completed\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mfutures\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 19\u001B[0;31m                 \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mplots\u001B[0m\u001B[0;34m+=\u001B[0m\u001B[0mfuture\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mresult\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     20\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mshow\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     21\u001B[0m         \u001B[0mprogress_bar\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtqdm\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mplots\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/opt/conda/lib/python3.8/concurrent/futures/_base.py\u001B[0m in \u001B[0;36mresult\u001B[0;34m(self, timeout)\u001B[0m\n\u001B[1;32m    430\u001B[0m                 \u001B[0;32mraise\u001B[0m \u001B[0mCancelledError\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    431\u001B[0m             \u001B[0;32melif\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_state\u001B[0m \u001B[0;34m==\u001B[0m \u001B[0mFINISHED\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 432\u001B[0;31m                 \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m__get_result\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    433\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    434\u001B[0m             \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_condition\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mwait\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtimeout\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/opt/conda/lib/python3.8/concurrent/futures/_base.py\u001B[0m in \u001B[0;36m__get_result\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    386\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0m__get_result\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    387\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_exception\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 388\u001B[0;31m             \u001B[0;32mraise\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_exception\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    389\u001B[0m         \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    390\u001B[0m             \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_result\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/opt/conda/lib/python3.8/concurrent/futures/thread.py\u001B[0m in \u001B[0;36mrun\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m     55\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     56\u001B[0m         \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 57\u001B[0;31m             \u001B[0mresult\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfn\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     58\u001B[0m         \u001B[0;32mexcept\u001B[0m \u001B[0mBaseException\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0mexc\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     59\u001B[0m             \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfuture\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mset_exception\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mexc\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m<ipython-input-50-bbedf88d208e>\u001B[0m in \u001B[0;36meda_on_text_data\u001B[0;34m(df)\u001B[0m\n\u001B[1;32m     14\u001B[0m             \u001B[0;31m#futures.append(executor.submit(plot_most_common_noun_phrases_barchart,df[column_name],column_name))\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     15\u001B[0m             \u001B[0;32mfor\u001B[0m \u001B[0mfuture\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mconcurrent\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfutures\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mas_completed\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mfutures\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 16\u001B[0;31m                 \u001B[0mplots\u001B[0m\u001B[0;34m+=\u001B[0m\u001B[0mfuture\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mresult\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     17\u001B[0m     \u001B[0;32mreturn\u001B[0m \u001B[0mplots\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     18\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/opt/conda/lib/python3.8/concurrent/futures/_base.py\u001B[0m in \u001B[0;36mresult\u001B[0;34m(self, timeout)\u001B[0m\n\u001B[1;32m    430\u001B[0m                 \u001B[0;32mraise\u001B[0m \u001B[0mCancelledError\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    431\u001B[0m             \u001B[0;32melif\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_state\u001B[0m \u001B[0;34m==\u001B[0m \u001B[0mFINISHED\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 432\u001B[0;31m                 \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m__get_result\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    433\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    434\u001B[0m             \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_condition\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mwait\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtimeout\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/opt/conda/lib/python3.8/concurrent/futures/_base.py\u001B[0m in \u001B[0;36m__get_result\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    386\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0m__get_result\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    387\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_exception\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 388\u001B[0;31m             \u001B[0;32mraise\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_exception\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    389\u001B[0m         \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    390\u001B[0m             \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_result\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/opt/conda/lib/python3.8/concurrent/futures/thread.py\u001B[0m in \u001B[0;36mrun\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m     55\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     56\u001B[0m         \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 57\u001B[0;31m             \u001B[0mresult\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfn\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     58\u001B[0m         \u001B[0;32mexcept\u001B[0m \u001B[0mBaseException\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0mexc\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     59\u001B[0m             \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfuture\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mset_exception\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mexc\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m<ipython-input-45-2e20f43385b9>\u001B[0m in \u001B[0;36mplot_top_non_stopwords_barchart\u001B[0;34m(text, title)\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[0;32mdef\u001B[0m \u001B[0mplot_top_non_stopwords_barchart\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtext\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0mtitle\u001B[0m \u001B[0;34m:\u001B[0m \u001B[0mstr\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 2\u001B[0;31m     \u001B[0mstop\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mset\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mstopwords\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mwords\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m'english'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      3\u001B[0m     \u001B[0mnew\u001B[0m\u001B[0;34m=\u001B[0m \u001B[0mtext\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mstr\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msplit\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      4\u001B[0m     \u001B[0mnew\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mnew\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mvalues\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtolist\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      5\u001B[0m     \u001B[0mcorpus\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/opt/conda/lib/python3.8/site-packages/nltk/corpus/util.py\u001B[0m in \u001B[0;36m__getattr__\u001B[0;34m(self, attr)\u001B[0m\n\u001B[1;32m    118\u001B[0m             \u001B[0;32mraise\u001B[0m \u001B[0mAttributeError\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"LazyCorpusLoader object has no attribute '__bases__'\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    119\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 120\u001B[0;31m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m__load\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    121\u001B[0m         \u001B[0;31m# This looks circular, but its not, since __load() changes our\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    122\u001B[0m         \u001B[0;31m# __class__ to something new:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/opt/conda/lib/python3.8/site-packages/nltk/corpus/util.py\u001B[0m in \u001B[0;36m__load\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m     83\u001B[0m                     \u001B[0mroot\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mnltk\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdata\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfind\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"{}/{}\"\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mformat\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msubdir\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mzip_name\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     84\u001B[0m                 \u001B[0;32mexcept\u001B[0m \u001B[0mLookupError\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 85\u001B[0;31m                     \u001B[0;32mraise\u001B[0m \u001B[0me\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     86\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     87\u001B[0m         \u001B[0;31m# Load the corpus.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/opt/conda/lib/python3.8/site-packages/nltk/corpus/util.py\u001B[0m in \u001B[0;36m__load\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m     78\u001B[0m         \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     79\u001B[0m             \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 80\u001B[0;31m                 \u001B[0mroot\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mnltk\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdata\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfind\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"{}/{}\"\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mformat\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msubdir\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m__name\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     81\u001B[0m             \u001B[0;32mexcept\u001B[0m \u001B[0mLookupError\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     82\u001B[0m                 \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/opt/conda/lib/python3.8/site-packages/nltk/data.py\u001B[0m in \u001B[0;36mfind\u001B[0;34m(resource_name, paths)\u001B[0m\n\u001B[1;32m    583\u001B[0m     \u001B[0msep\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m\"*\"\u001B[0m \u001B[0;34m*\u001B[0m \u001B[0;36m70\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    584\u001B[0m     \u001B[0mresource_not_found\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m\"\\n%s\\n%s\\n%s\\n\"\u001B[0m \u001B[0;34m%\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0msep\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmsg\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0msep\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 585\u001B[0;31m     \u001B[0;32mraise\u001B[0m \u001B[0mLookupError\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mresource_not_found\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    586\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    587\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mLookupError\u001B[0m: \n**********************************************************************\n  Resource \u001B[93mstopwords\u001B[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001B[31m>>> import nltk\n  >>> nltk.download('stopwords')\n  \u001B[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001B[93mcorpora/stopwords\u001B[0m\n\n  Searched in:\n    - '/home/jovyan/nltk_data'\n    - '/opt/conda/nltk_data'\n    - '/opt/conda/share/nltk_data'\n    - '/opt/conda/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n**********************************************************************\n"
     ]
    }
   ],
   "source": [
    "eda_pwdb.execute()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [],
   "source": [
    "#eda_pwdb.show()\n",
    "#eda_pwdb.export_to_html(OUTPUT_FILE_PATH)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}