{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Reusable classes\n",
    "import sys\n",
    "sys.path.append(\"/home/jovyan/work/upload/ml-experiments/sc_wrangling\")\n",
    "\n",
    "# Data path\n",
    "import pathlib\n",
    "FOLDER = pathlib.Path(\"/home/jovyan/work/upload/\")\n",
    "TABLE_PATH = FOLDER / 'data/pickle/df_columns_labels.pkl'\n",
    "LAW2VEC_PATH = FOLDER / 'data/law2vec/Law2Vec.200d.txt'\n",
    "\n",
    "# Manage ML lifecycle\n",
    "import mlflow\n",
    "from mlflow import log_params, set_tags, log_metrics\n",
    "MLFLOW_TRACKING_URI = 'http://srv.meaningfy.ws:8989'\n",
    "\n",
    "# Math stuff\n",
    "import numpy as np\n",
    "\n",
    "# Data visualisation\n",
    "import pandas as pd\n",
    "\n",
    "# Vectorize algotrithm\n",
    "from gensim.models import Word2Vec, KeyedVectors\n",
    "\n",
    "# Support Vector Classifier Algorithm\n",
    "from sklearn.svm import SVC\n",
    "# :gamma: is a parameter for non linear hyperplanes. The higher the gamma\n",
    "#         value it tries to exactly fit the training data set.\n",
    "GAMMA = 3\n",
    "# :C: is the penalty parameter of the error term. It controls the trade\n",
    "#     off between smooth decision boundary and classifying the training points correctly.\n",
    "#     !!! Increasing C values may lead to overfitting the training data. !!!\n",
    "C = 2\n",
    "\n",
    "# Intermediate steps of the pipeline must be ‘transforms’,\n",
    "# that is, they must implement fit and transform methods.\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Splitting data into train and test\n",
    "from sklearn.model_selection import train_test_split\n",
    "RANDOM_STATE = 42\n",
    "# Where \"train\" contains 70% of data and \"test\" - 30%\n",
    "TEST_SIZE = 0.3\n",
    "SHUFFLE = True\n",
    "\n",
    "# Mean embedding function\n",
    "from mean_vectorizer import MeanEmbeddingVectorizerLaw2Vec\n",
    "\n",
    "# Metrics Evaluation Methods\n",
    "from evaluation_metrics import model_evaluation_metrics\n",
    "\n",
    "# Transform DataFrame to dictionary\n",
    "from dictionary_transformation import series_pair_to_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# Read data\n",
    "df = pd.read_pickle(TABLE_PATH)\n",
    "# Independent data\n",
    "columns = df['Concatenated Data (clean)']\n",
    "# Label data\n",
    "category = df['Subcategory']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## law2vec model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# Load a word2vec model stored in the C *text* format.\n",
    "model = KeyedVectors.load_word2vec_format(LAW2VEC_PATH, binary=False)\n",
    "l2v_dict = {w: vec for w, vec in zip(model.wv.index2word, model.wv.syn0)}\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "# Use pipes to implement steps of fit and transform method\n",
    "svm_l2v = Pipeline([\n",
    "    # Add the words we want to mean\n",
    "    (\"law2vec vectorizer\", MeanEmbeddingVectorizerLaw2Vec(l2v_dict)),\n",
    "    # Use SVC algorithm\n",
    "    # :gamma: is a parameter for non linear hyperplanes. The higher the gamma\n",
    "    #         value it tries to exactly fit the training data set.\n",
    "    #\n",
    "    # :C: is the penalty parameter of the error term. It controls the trade\n",
    "    #     off between smooth decision boundary and classifying the training points correctly.\n",
    "    #     !!! Increasing C values may lead to overfitting the training data. !!!\n",
    "    (\"SVM\", SVC(gamma=GAMMA, C=C))])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Train SVM Model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "# split data into test and train sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    columns, category, random_state=RANDOM_STATE, test_size=TEST_SIZE, shuffle=SHUFFLE)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "Pipeline(steps=[('law2vec vectorizer',\n                 <mean_vectorizer.MeanEmbeddingVectorizerLaw2Vec object at 0x7f03ce704130>),\n                ('SVM', SVC(C=2, gamma=3))])"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit SVM model with out train data\n",
    "svm_l2v.fit(X_train, y_train)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "0.9862385321100917"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model Evaluation\n",
    "svm_l2v.score(X_train, y_train)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "array([14, 11,  0,  2, 20,  9, 10, 10, 10, 12, 10, 22, 10,  0,  0, 21, 12,\n       33, 21,  9, 14, 10,  0, 10, 12,  0, 10,  2, 12, 20, 24, 14, 14, 10,\n        0, 20, 21, 16,  2,  9,  4, 24, 26, 21, 14, 29, 30, 20,  9, 30, 26,\n       20, 14, 26, 28, 14,  9, 14, 12,  9, 14, 10,  0,  2,  9,  0, 16, 14,\n       20, 10,  2, 10,  0,  0, 27, 10, 12, 14, 15, 21, 24,  4,  0, 10, 10,\n        0,  0, 21, 21, 10, 10,  0,  0, 14, 27, 13,  9, 10,  0, 10, 10, 10,\n       14, 21, 14, 10, 10, 20,  9, 21,  2,  0,  9,  0, 22, 14,  2, 20,  9,\n       10,  9, 14,  9, 12,  2, 26, 14, 26, 10, 20, 10,  9,  9,  9, 10, 21,\n       10, 10,  2,  9, 19, 21,  4, 20, 21, 16, 10, 10,  2, 30,  0, 14, 18,\n       14, 22,  2, 10,  0,  4, 10,  0, 21,  4, 14, 22, 10, 30, 10, 12,  9,\n        2, 27, 30, 22, 20, 10, 10, 10, 13,  0, 26,  4, 14, 10,  0,  0,  0,\n       10, 13, 10, 10, 21, 15, 10, 19, 30, 22,  0, 18, 30, 21, 22,  0, 14,\n       10, 14,  4, 12,  0, 19, 14, 10, 10, 30,  0,  9,  2,  9, 10,  0, 10,\n       16, 20, 27, 30, 10, 21,  0, 22, 26, 12,  9, 10, 10, 34, 21, 10,  4,\n       30, 10,  0, 12, 24, 21,  0,  9, 12,  4, 26,  0, 12,  4, 20, 14, 19,\n       14,  2, 10,  2, 29, 24,  2,  2, 20, 20,  0, 16, 10,  0, 14, 10, 12,\n       20,  4, 22, 14,  0, 22, 10, 10,  2])"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SVM prediction based on test data\n",
    "prediction = svm_l2v.predict(X_test)\n",
    "prediction"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Evaluation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "evaluation = model_evaluation_metrics(y_test, prediction, 'Subategory')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "# Transform columns data to dict to use in MLFlow\n",
    "transformation = series_pair_to_dict(evaluation, 'Evaluation Metrics', 'Subategory')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "mlflow.set_tracking_uri(MLFLOW_TRACKING_URI)\n",
    "mlflow.set_experiment(experiment_name=\"Subategory (Law2Vec)\")\n",
    "\n",
    "with mlflow.start_run():\n",
    "\n",
    "    parameters = {\"Language model\": 'law2vec',\n",
    "                  \"Random state\": RANDOM_STATE,\n",
    "                  \"Test size\": TEST_SIZE,\n",
    "                  \"Shuffle\": SHUFFLE,\n",
    "                  \"Gamma\": GAMMA,\n",
    "                  \"C\": C}\n",
    "    log_params(parameters)\n",
    "\n",
    "    log_metrics(transformation)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}