{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Word2vec model training\n",
    "#### Model training based on three datasets' text data:\n",
    "- M1: pwdb + eu_timeline  ( +  ireland_timeline )\n",
    "- M2: ds_eu_cellar\n",
    "- M3: M1+M2\n",
    "\n",
    "#### Extract NOUN and NOUN PHRASES from each text data\n",
    "#### Train the word2vec model with each dataset's textual data"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Import libraries"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Since the GPL-licensed package `unidecode` is not installed, using Python's `unicodedata` package which yields worse results.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "from IPython.core.display import display\n",
    "from spacy.tokens.doc import Doc\n",
    "\n",
    "sys.path.append(\"/home/jovyan/work/sem-covid/\")\n",
    "sys.path = list(set(sys.path))\n",
    "\n",
    "import os\n",
    "\n",
    "os.getcwd()\n",
    "os.chdir('/home/jovyan/work/sem-covid/')\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "\n",
    "from typing import List, Tuple\n",
    "\n",
    "import spacy\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "import pandas as pd\n",
    "from gensim.models import Word2Vec\n",
    "import plotly.express as px\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sem_covid.services.data_registry import Dataset\n",
    "from sem_covid.adapters.data_source import IndexTabularDataSource\n",
    "\n",
    "from sem_covid.entrypoints.notebooks.topic_modeling.topic_modeling_wrangling.token_management import (filter_pos,\n",
    "    select_pos, filter_pos, filter_stop_words)\n",
    "\n",
    "from sem_covid.services.sc_wrangling.data_cleaning import (clean_text_from_specific_characters, clean_fix_unicode,\n",
    "                                                           clean_remove_currency_symbols, clean_remove_emails,\n",
    "                                                           clean_remove_urls, clean_remove_stopwords)\n",
    "\n",
    "from sem_covid.entrypoints.notebooks.language_modeling.language_model_tools.similarity_calculus import (\n",
    "    euclidean_similarity, manhattan_similarity, cosine_similarity, get_similarity_matrix)\n",
    "\n",
    "from sem_covid.entrypoints.notebooks.language_modeling.language_model_tools.document_handling_tools import(\n",
    "    document_atomization_noun_phrases, lemmatize_document)\n",
    "\n",
    "from sem_covid.entrypoints.notebooks.language_modeling.language_model_tools.word_embeddings_handler import (\n",
    "    select_words_and_embedding_clusters, create_tsne_model, create_word_clusters_matrix)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Define constants"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "PWDB_TEXTUAL_CLASS = ['title', 'background_info_description', 'content_of_measure_description',\n",
    "                      'use_of_measure_description', 'involvement_of_social_partners_description']\n",
    "\n",
    "DEFAULT_TEXTUAL_COLUMN = ['title']\n",
    "WINDOW = 5\n",
    "MIN_COUNT = 1\n",
    "VECTOR_SIZE = 300\n",
    "EPOCHS = 50\n",
    "EU_TIMELINE_TOTAL_EXAMPLES = 171\n",
    "IRELAND_TIMELINE_TOTAL_EXAMPLES = 410\n",
    "EU_CELLAR_TOTAL_EXAMPLES = 2653"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Data preprocessing\n",
    "- data cleanup\n",
    "- turn corpus into spacy document"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "def apply_cleaning_functions(document_corpus: pd.Series) -> pd.Series:\n",
    "    \"\"\"\n",
    "    This function receives the document and leads through cleaning steps\n",
    "    Args:\n",
    "        document_corpus: dataset document corpus\n",
    "\n",
    "    Returns: clean document corpus\n",
    "    \"\"\"\n",
    "    unused_characters = [\"\\\\r\", \">\", \"\\n\", \"\\\\\", \"<\", \"''\", \"%\", \"...\", \"\\'\", '\"', \"(\", \"\\n\", \"*\", \"1)\", \"2)\", \"3)\",\n",
    "                         \"[\", \"]\", \"-\", \"_\", \"\\r\"]\n",
    "\n",
    "    new_document_corpus = document_corpus.apply(clean_text_from_specific_characters, characters=unused_characters)\n",
    "    new_document_corpus = new_document_corpus.apply(clean_fix_unicode)\n",
    "    new_document_corpus = new_document_corpus.apply(clean_remove_urls)\n",
    "    new_document_corpus = new_document_corpus.apply(clean_remove_emails)\n",
    "    new_document_corpus = new_document_corpus.apply(clean_remove_currency_symbols)\n",
    "    new_document_corpus = new_document_corpus.apply(clean_remove_stopwords)\n",
    "\n",
    "    return new_document_corpus\n",
    "\n",
    "def generate_graph(sm: pd.DataFrame, graph: nx.Graph, root_word: str, kn: int,threshold:np.float64 = 0.8, deep_level: int = 0,max_deep_level:int = 2 ) -> nx.Graph:\n",
    "    if deep_level>max_deep_level:\n",
    "        return graph\n",
    "    new_nodes = sm[root_word].sort_values(ascending=False)[:kn].index.to_list()\n",
    "    new_nodes_weight = list(sm[root_word].sort_values(ascending=False)[:kn].values)\n",
    "    for index in range(0,len(new_nodes)):\n",
    "        if new_nodes_weight[index] >= threshold:\n",
    "            graph.add_edge(root_word,new_nodes[index])\n",
    "            generate_graph(sm,graph,new_nodes[index],kn-1,threshold,deep_level+1,max_deep_level)\n",
    "    return graph"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "class LanguageModelPipeline:\n",
    "    \"\"\"\n",
    "        This pipeline executes the steps for word2vec language training.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, dataset_sources: List[Tuple[IndexTabularDataSource, List[str]]]):\n",
    "        \"\"\"\n",
    "            :param dataset_sources: represents the source of the datasets.\n",
    "        \"\"\"\n",
    "        self.dataset_sources = dataset_sources\n",
    "        self.documents_corpus = pd.Series()\n",
    "        self.word2vec = None\n",
    "\n",
    "    def download_datasets(self):\n",
    "        \"\"\"\n",
    "            In this step it will download the dataset and detect selected columns.\n",
    "            It can be downloaded as many datasets as there are in data source.\n",
    "        \"\"\"\n",
    "        self.dataset_sources = [(dataset_columns, dataset_source.fetch())\n",
    "                                for dataset_source, dataset_columns in self.dataset_sources]\n",
    "\n",
    "    def extract_textual_data(self):\n",
    "        \"\"\"\n",
    "            After downloading the datasets, the textual data will be found and and concatenated\n",
    "            with executing of several steps as well. It will fill the NaN values with empty space,\n",
    "            add a dot at the end of each concatenated column and reset the index.\n",
    "        \"\"\"\n",
    "        self.documents_corpus = pd.concat([dataset[columns]\n",
    "                                          .fillna(value=\"\")\n",
    "                                          .agg('. '.join, axis=1)\n",
    "                                          .reset_index(drop=True)\n",
    "                                           for columns, dataset in self.dataset_sources\n",
    "                                           ], ignore_index=True)\n",
    "\n",
    "    def clean_textual_data(self):\n",
    "        \"\"\"\n",
    "            The next step is data cleaning. In this step the function \"apply_cleaning_functions\"\n",
    "            applies the following actions:\n",
    "                - clean the document from specific characters\n",
    "                - delete unicode\n",
    "                - removes emails and URLs and currency symbols\n",
    "        \"\"\"\n",
    "        self.documents_corpus = apply_cleaning_functions(self.documents_corpus)\n",
    "\n",
    "    def transform_to_spacy_doc(self):\n",
    "        \"\"\"\n",
    "            When the document is clean, is going to be transform into spacy document\n",
    "        \"\"\"\n",
    "        self.documents_corpus = self.documents_corpus.apply(nlp)\n",
    "\n",
    "    def extract_features(self):\n",
    "        \"\"\"\n",
    "            To extract the parts of speech, below it was defined classes for each token is necessary.\n",
    "        \"\"\"\n",
    "        self.documents_corpus = pd.concat([self.documents_corpus,\n",
    "                                           self.documents_corpus.apply(document_atomization_noun_phrases),\n",
    "                                           self.documents_corpus.apply(lemmatize_document)]\n",
    "                                           ,ignore_index=True)\n",
    "\n",
    "        self.documents_corpus = self.documents_corpus.apply(lambda x: list(map(str, x)))\n",
    "\n",
    "    def model_training(self):\n",
    "        \"\"\"\n",
    "            When the data is prepared it's stored into Word2Vec model.\n",
    "        \"\"\"\n",
    "        self.word2vec = Word2Vec(sentences=self.documents_corpus, window=WINDOW,\n",
    "                                 min_count=MIN_COUNT, vector_size=VECTOR_SIZE)\n",
    "\n",
    "    def execute(self):\n",
    "        \"\"\"\n",
    "            The final step is execution, where are stored each step and it will be executed in a row\n",
    "        \"\"\"\n",
    "        self.download_datasets()\n",
    "        self.extract_textual_data()\n",
    "        self.clean_textual_data()\n",
    "        self.transform_to_spacy_doc()\n",
    "        self.extract_features()\n",
    "        self.model_training()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Experiment Nr#1 language model based on:\n",
    "- PWDB\n",
    "- eu-timeline\n",
    "- ireland-timeline"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (1288 of 1288) |####################| Elapsed Time: 0:00:00 Time:  0:00:00\n",
      "100% (171 of 171) |######################| Elapsed Time: 0:00:00 Time:  0:00:00\n",
      "100% (410 of 410) |######################| Elapsed Time: 0:00:00 Time:  0:00:00\n"
     ]
    }
   ],
   "source": [
    "dataset_sources_config = [\n",
    "    (Dataset.PWDB, PWDB_TEXTUAL_CLASS),\n",
    "    (Dataset.EU_ACTION_TIMELINE, DEFAULT_TEXTUAL_COLUMN),\n",
    "    (Dataset.IRELAND_ACTION_TIMELINE, DEFAULT_TEXTUAL_COLUMN)\n",
    "]\n",
    "model1_language_model_pipeline = LanguageModelPipeline(dataset_sources=dataset_sources_config)\n",
    "model1_language_model_pipeline.execute()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Experiment Nr#2 language model based on:\n",
    "- eu-cellar\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (2653 of 2653) |####################| Elapsed Time: 0:00:01 Time:  0:00:01\n"
     ]
    }
   ],
   "source": [
    "dataset_sources_config = [\n",
    "    (Dataset.EU_CELLAR, DEFAULT_TEXTUAL_COLUMN)\n",
    "]\n",
    "model2_language_model_pipeline = LanguageModelPipeline(dataset_sources=dataset_sources_config)\n",
    "model2_language_model_pipeline.execute()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "# doc = nlp(str(model2_language_model_pipeline.word2vec.wv.index_to_key))\n",
    "# selected_pos = select_pos(doc, pos=['NOUN', 'ADJ'])\n",
    "#"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "# selected_pos = list(map(str, selected_pos))\n",
    "#"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "# key_words = ['work', 'agreement', 'working', 'companies', 'workers',\n",
    "#              'measures', 'temporary', 'social', 'support', 'covid19',\n",
    "#              '2020', 'public', 'national', 'ireland', 'statement', '2021',\n",
    "#              'announce', 'health', 'minister', 'new', 'billion', 'coronavirus',\n",
    "#              'vaccine', 'eur', 'support', 'million', 'commission', 'eu']\n",
    "# selected_key_words = [ word for word in key_words if word in selected_pos]\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "# selected_pos_index = [model2_language_model_pipeline.word2vec.wv.index_to_key.index(token)\n",
    "#                       for token in selected_pos\n",
    "#                       if token in model2_language_model_pipeline.word2vec.wv.index_to_key]\n",
    "#"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "# selected_pos_embeddings = [model2_language_model_pipeline.word2vec.wv.vectors[index]\n",
    "#                            for index in selected_pos_index]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "# sim_matrix =  my_get_similarity_matrix(selected_pos_embeddings,\n",
    "#                       selected_pos,\n",
    "#                       metric=cosine_similarity)\n",
    "# sim_matrix\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "# for index in range(0, len(selected_key_words)):\n",
    "#     graph = generate_graph(sim_matrix,nx.Graph(),selected_key_words[index],4,max_deep_level=2, threshold=0.7)\n",
    "#     plt.figure(index,figsize=(10,10))\n",
    "#     plt.title(selected_key_words[index])\n",
    "#     nx.draw_spring(graph, with_labels=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Experiment Nr#3 language model based on:\n",
    "- PWDB\n",
    "- eu-timeline\n",
    "- ireland-timeline\n",
    "- eu-cellar"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "dataset_sources_config = [\n",
    "    (Dataset.PWDB, PWDB_TEXTUAL_CLASS),\n",
    "    (Dataset.EU_ACTION_TIMELINE, DEFAULT_TEXTUAL_COLUMN),\n",
    "    (Dataset.IRELAND_ACTION_TIMELINE, DEFAULT_TEXTUAL_COLUMN),\n",
    "    (Dataset.EU_CELLAR, DEFAULT_TEXTUAL_COLUMN)\n",
    "]\n",
    "model3_language_model_pipeline = LanguageModelPipeline(dataset_sources=dataset_sources_config)\n",
    "model3_language_model_pipeline.execute()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "model2_document = nlp(str(model2_language_model_pipeline.word2vec.wv.index_to_key))\n",
    "model2_selected_pos = select_pos(model2_document, pos=['NOUN', 'ADJ'])\n",
    "model2_selected_pos = list(map(str, model2_selected_pos))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "key_words = ['work', 'agreement', 'working', 'companies', 'workers',\n",
    "             'measures', 'temporary', 'social', 'support', 'covid19',\n",
    "             '2020', 'public', 'national', 'ireland', 'statement', '2021',\n",
    "             'announce', 'health', 'minister', 'new', 'billion', 'coronavirus',\n",
    "             'vaccine', 'eur', 'support', 'million', 'commission', 'eu']\n",
    "\n",
    "\n",
    "\n",
    "model2_selected_key_words = [ word for word in key_words if word in model2_selected_pos]\n",
    "model2_selected_pos_index = [model2_language_model_pipeline.word2vec.wv.index_to_key.index(token)\n",
    "                      for token in model2_selected_pos\n",
    "                      if token in model2_language_model_pipeline.word2vec.wv.index_to_key]\n",
    "model2_selected_pos_embeddings = [model2_language_model_pipeline.word2vec.wv.vectors[index]\n",
    "                           for index in model2_selected_pos_index]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Similarity matrices\n",
    "### Euclidean similarity"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "# model1_euclidean_similarity_matrix = get_similarity_matrix(selected_pos_embeddings,\n",
    "#                                                            selected_pos,\n",
    "#                                                            metric=euclidean_similarity)\n",
    "# model1_euclidean_similarity_matrix"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "data": {
      "text/plain": "            european   council  regulation  commission  parliament  decision  \\\neuropean    1.000000  0.092975    0.068035    0.078721    0.084919  0.067845   \ncouncil     0.092975  1.000000    0.077712    0.089045    0.081967  0.067675   \nregulation  0.068035  0.077712    1.000000    0.067661    0.081639  0.084227   \ncommission  0.078721  0.089045    0.067661    1.000000    0.080171  0.074055   \nparliament  0.084919  0.081967    0.081639    0.080171    1.000000  0.068253   \n...              ...       ...         ...         ...         ...       ...   \npave        0.070028  0.069539    0.064439    0.082983    0.065430  0.077736   \noverride    0.070207  0.069735    0.064759    0.083314    0.065690  0.078059   \nbalkan      0.070257  0.069861    0.064867    0.083325    0.065763  0.078216   \nleader      0.070087  0.069663    0.064702    0.083361    0.065623  0.078179   \nshortage    0.070256  0.069772    0.064796    0.083318    0.065731  0.078096   \n\n            committee      case  document     union  ...  wastewater  \\\neuropean     0.076907  0.039055  0.064252  0.074069  ...    0.070132   \ncouncil      0.067401  0.038438  0.066541  0.069604  ...    0.069701   \nregulation   0.054282  0.037151  0.056214  0.059274  ...    0.064737   \ncommission   0.064334  0.043303  0.084105  0.065690  ...    0.083329   \nparliament   0.065765  0.037646  0.062161  0.070635  ...    0.065632   \n...               ...       ...       ...       ...  ...         ...   \npave         0.065999  0.056018  0.063948  0.070418  ...    0.865758   \noverride     0.066043  0.055863  0.064151  0.070653  ...    0.919818   \nbalkan       0.066001  0.055830  0.064080  0.070653  ...    0.896481   \nleader       0.065981  0.056002  0.064161  0.070654  ...    0.906094   \nshortage     0.065995  0.055920  0.064146  0.070611  ...    0.912072   \n\n            salamander  supplier  donation  grandfathere      pave  override  \\\neuropean      0.070232  0.070103  0.070190      0.070135  0.070028  0.070207   \ncouncil       0.069711  0.069643  0.069696      0.069645  0.069539  0.069735   \nregulation    0.064743  0.064671  0.064674      0.064639  0.064439  0.064759   \ncommission    0.083231  0.083258  0.083302      0.083167  0.082983  0.083314   \nparliament    0.065639  0.065574  0.065654      0.065578  0.065430  0.065690   \n...                ...       ...       ...           ...       ...       ...   \npave          0.874539  0.854341  0.891273      0.897697  1.000000  0.875922   \noverride      0.921074  0.891209  0.918554      0.915038  0.875922  1.000000   \nbalkan        0.893802  0.867420  0.872706      0.890004  0.856431  0.891130   \nleader        0.869230  0.857809  0.877381      0.864832  0.837585  0.887445   \nshortage      0.918657  0.877545  0.902239      0.901154  0.867423  0.924946   \n\n              balkan    leader  shortage  \neuropean    0.070257  0.070087  0.070256  \ncouncil     0.069861  0.069663  0.069772  \nregulation  0.064867  0.064702  0.064796  \ncommission  0.083325  0.083361  0.083318  \nparliament  0.065763  0.065623  0.065731  \n...              ...       ...       ...  \npave        0.856431  0.837585  0.867423  \noverride    0.891130  0.887445  0.924946  \nbalkan      1.000000  0.858806  0.912305  \nleader      0.858806  1.000000  0.879809  \nshortage    0.912305  0.879809  1.000000  \n\n[3424 rows x 3424 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>european</th>\n      <th>council</th>\n      <th>regulation</th>\n      <th>commission</th>\n      <th>parliament</th>\n      <th>decision</th>\n      <th>committee</th>\n      <th>case</th>\n      <th>document</th>\n      <th>union</th>\n      <th>...</th>\n      <th>wastewater</th>\n      <th>salamander</th>\n      <th>supplier</th>\n      <th>donation</th>\n      <th>grandfathere</th>\n      <th>pave</th>\n      <th>override</th>\n      <th>balkan</th>\n      <th>leader</th>\n      <th>shortage</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>european</th>\n      <td>1.000000</td>\n      <td>0.092975</td>\n      <td>0.068035</td>\n      <td>0.078721</td>\n      <td>0.084919</td>\n      <td>0.067845</td>\n      <td>0.076907</td>\n      <td>0.039055</td>\n      <td>0.064252</td>\n      <td>0.074069</td>\n      <td>...</td>\n      <td>0.070132</td>\n      <td>0.070232</td>\n      <td>0.070103</td>\n      <td>0.070190</td>\n      <td>0.070135</td>\n      <td>0.070028</td>\n      <td>0.070207</td>\n      <td>0.070257</td>\n      <td>0.070087</td>\n      <td>0.070256</td>\n    </tr>\n    <tr>\n      <th>council</th>\n      <td>0.092975</td>\n      <td>1.000000</td>\n      <td>0.077712</td>\n      <td>0.089045</td>\n      <td>0.081967</td>\n      <td>0.067675</td>\n      <td>0.067401</td>\n      <td>0.038438</td>\n      <td>0.066541</td>\n      <td>0.069604</td>\n      <td>...</td>\n      <td>0.069701</td>\n      <td>0.069711</td>\n      <td>0.069643</td>\n      <td>0.069696</td>\n      <td>0.069645</td>\n      <td>0.069539</td>\n      <td>0.069735</td>\n      <td>0.069861</td>\n      <td>0.069663</td>\n      <td>0.069772</td>\n    </tr>\n    <tr>\n      <th>regulation</th>\n      <td>0.068035</td>\n      <td>0.077712</td>\n      <td>1.000000</td>\n      <td>0.067661</td>\n      <td>0.081639</td>\n      <td>0.084227</td>\n      <td>0.054282</td>\n      <td>0.037151</td>\n      <td>0.056214</td>\n      <td>0.059274</td>\n      <td>...</td>\n      <td>0.064737</td>\n      <td>0.064743</td>\n      <td>0.064671</td>\n      <td>0.064674</td>\n      <td>0.064639</td>\n      <td>0.064439</td>\n      <td>0.064759</td>\n      <td>0.064867</td>\n      <td>0.064702</td>\n      <td>0.064796</td>\n    </tr>\n    <tr>\n      <th>commission</th>\n      <td>0.078721</td>\n      <td>0.089045</td>\n      <td>0.067661</td>\n      <td>1.000000</td>\n      <td>0.080171</td>\n      <td>0.074055</td>\n      <td>0.064334</td>\n      <td>0.043303</td>\n      <td>0.084105</td>\n      <td>0.065690</td>\n      <td>...</td>\n      <td>0.083329</td>\n      <td>0.083231</td>\n      <td>0.083258</td>\n      <td>0.083302</td>\n      <td>0.083167</td>\n      <td>0.082983</td>\n      <td>0.083314</td>\n      <td>0.083325</td>\n      <td>0.083361</td>\n      <td>0.083318</td>\n    </tr>\n    <tr>\n      <th>parliament</th>\n      <td>0.084919</td>\n      <td>0.081967</td>\n      <td>0.081639</td>\n      <td>0.080171</td>\n      <td>1.000000</td>\n      <td>0.068253</td>\n      <td>0.065765</td>\n      <td>0.037646</td>\n      <td>0.062161</td>\n      <td>0.070635</td>\n      <td>...</td>\n      <td>0.065632</td>\n      <td>0.065639</td>\n      <td>0.065574</td>\n      <td>0.065654</td>\n      <td>0.065578</td>\n      <td>0.065430</td>\n      <td>0.065690</td>\n      <td>0.065763</td>\n      <td>0.065623</td>\n      <td>0.065731</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>pave</th>\n      <td>0.070028</td>\n      <td>0.069539</td>\n      <td>0.064439</td>\n      <td>0.082983</td>\n      <td>0.065430</td>\n      <td>0.077736</td>\n      <td>0.065999</td>\n      <td>0.056018</td>\n      <td>0.063948</td>\n      <td>0.070418</td>\n      <td>...</td>\n      <td>0.865758</td>\n      <td>0.874539</td>\n      <td>0.854341</td>\n      <td>0.891273</td>\n      <td>0.897697</td>\n      <td>1.000000</td>\n      <td>0.875922</td>\n      <td>0.856431</td>\n      <td>0.837585</td>\n      <td>0.867423</td>\n    </tr>\n    <tr>\n      <th>override</th>\n      <td>0.070207</td>\n      <td>0.069735</td>\n      <td>0.064759</td>\n      <td>0.083314</td>\n      <td>0.065690</td>\n      <td>0.078059</td>\n      <td>0.066043</td>\n      <td>0.055863</td>\n      <td>0.064151</td>\n      <td>0.070653</td>\n      <td>...</td>\n      <td>0.919818</td>\n      <td>0.921074</td>\n      <td>0.891209</td>\n      <td>0.918554</td>\n      <td>0.915038</td>\n      <td>0.875922</td>\n      <td>1.000000</td>\n      <td>0.891130</td>\n      <td>0.887445</td>\n      <td>0.924946</td>\n    </tr>\n    <tr>\n      <th>balkan</th>\n      <td>0.070257</td>\n      <td>0.069861</td>\n      <td>0.064867</td>\n      <td>0.083325</td>\n      <td>0.065763</td>\n      <td>0.078216</td>\n      <td>0.066001</td>\n      <td>0.055830</td>\n      <td>0.064080</td>\n      <td>0.070653</td>\n      <td>...</td>\n      <td>0.896481</td>\n      <td>0.893802</td>\n      <td>0.867420</td>\n      <td>0.872706</td>\n      <td>0.890004</td>\n      <td>0.856431</td>\n      <td>0.891130</td>\n      <td>1.000000</td>\n      <td>0.858806</td>\n      <td>0.912305</td>\n    </tr>\n    <tr>\n      <th>leader</th>\n      <td>0.070087</td>\n      <td>0.069663</td>\n      <td>0.064702</td>\n      <td>0.083361</td>\n      <td>0.065623</td>\n      <td>0.078179</td>\n      <td>0.065981</td>\n      <td>0.056002</td>\n      <td>0.064161</td>\n      <td>0.070654</td>\n      <td>...</td>\n      <td>0.906094</td>\n      <td>0.869230</td>\n      <td>0.857809</td>\n      <td>0.877381</td>\n      <td>0.864832</td>\n      <td>0.837585</td>\n      <td>0.887445</td>\n      <td>0.858806</td>\n      <td>1.000000</td>\n      <td>0.879809</td>\n    </tr>\n    <tr>\n      <th>shortage</th>\n      <td>0.070256</td>\n      <td>0.069772</td>\n      <td>0.064796</td>\n      <td>0.083318</td>\n      <td>0.065731</td>\n      <td>0.078096</td>\n      <td>0.065995</td>\n      <td>0.055920</td>\n      <td>0.064146</td>\n      <td>0.070611</td>\n      <td>...</td>\n      <td>0.912072</td>\n      <td>0.918657</td>\n      <td>0.877545</td>\n      <td>0.902239</td>\n      <td>0.901154</td>\n      <td>0.867423</td>\n      <td>0.924946</td>\n      <td>0.912305</td>\n      <td>0.879809</td>\n      <td>1.000000</td>\n    </tr>\n  </tbody>\n</table>\n<p>3424 rows × 3424 columns</p>\n</div>"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2_euclidean_similarity_matrix = get_similarity_matrix(model2_selected_pos_embeddings,\n",
    "                                                           model2_selected_pos,\n",
    "                                                           metric=euclidean_similarity)\n",
    "model2_euclidean_similarity_matrix"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "# % % time\n",
    "# model3_euclidean_similarity_matrix = get_similarity_matrix(model3_language_model_pipeline.word2vec.wv.vectors[:100],\n",
    "#                                                            model3_language_model_pipeline.word2vec.wv.index_to_key[\n",
    "#                                                            :100],\n",
    "#                                                            metric=euclidean_similarity)\n",
    "# model3_euclidean_similarity_matrix"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Cosine similarity"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "# % % time\n",
    "# model1_cosine_similarity_matrix = get_similarity_matrix(model1_language_model_pipeline.word2vec.wv.vectors[:100],\n",
    "#                                                         model1_language_model_pipeline.word2vec.wv.index_to_key[:100],\n",
    "#                                                         metric=cosine_similarity)\n",
    "# model1_cosine_similarity_matrix"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 27s, sys: 7.14 ms, total: 1min 27s\n",
      "Wall time: 1min 28s\n"
     ]
    },
    {
     "data": {
      "text/plain": "            european   council  regulation  commission  parliament  decision  \\\neuropean    1.000000  0.731201    0.514220    0.548412    0.694949  0.404390   \ncouncil     0.731201  1.000000    0.638280    0.662799    0.672104  0.406194   \nregulation  0.514220  0.638280    1.000000    0.441102    0.692700  0.674442   \ncommission  0.548412  0.662799    0.441102    1.000000    0.613464  0.402439   \nparliament  0.694949  0.672104    0.692700    0.613464    1.000000  0.463719   \n...              ...       ...         ...         ...         ...       ...   \npave       -0.158955 -0.214734   -0.466323   -0.229820   -0.344435 -0.310094   \noverride    0.138907  0.108973    0.136758    0.158406    0.134858  0.109988   \nbalkan      0.189467  0.282464    0.304889    0.142213    0.237483  0.283080   \nleader     -0.044983 -0.012073    0.010416    0.131800   -0.000669  0.171448   \nshortage    0.206253  0.159523    0.194927    0.146521    0.197068  0.148615   \n\n            committee      case  document     union  ...  wastewater  \\\neuropean     0.619209 -0.317524  0.457604  0.552975  ...   -0.000420   \ncouncil      0.496312 -0.354882  0.499966  0.492518  ...    0.039089   \nregulation   0.259965 -0.358772  0.333145  0.343419  ...    0.077706   \ncommission   0.355325 -0.213437  0.672117  0.319866  ...    0.159323   \nparliament   0.500321 -0.339536  0.453496  0.541798  ...    0.008435   \n...               ...       ...       ...       ...  ...         ...   \npave         0.240334  0.674720 -0.139408 -0.125918  ...    0.264287   \noverride     0.389345  0.373732  0.284375  0.280294  ...    0.720038   \nbalkan       0.243165  0.223026  0.102062  0.228592  ...    0.595013   \nleader       0.150688  0.448404  0.178180  0.164615  ...    0.867434   \nshortage     0.254271  0.480956  0.243255  0.180428  ...    0.687595   \n\n            salamander  supplier  donation  grandfathere      pave  override  \\\neuropean      0.181652 -0.056360  0.107092      0.003446 -0.158955  0.138907   \ncouncil       0.060783 -0.065754  0.033837     -0.075030 -0.214734  0.108973   \nregulation    0.098298 -0.057382 -0.051784     -0.153557 -0.466323  0.136758   \ncommission    0.047444  0.083379  0.144360     -0.045840 -0.229820  0.158406   \nparliament    0.023199 -0.115383  0.057549     -0.125723 -0.344435  0.134858   \n...                ...       ...       ...           ...       ...       ...   \npave          0.318491  0.013521  0.500347      0.537758  1.000000  0.321711   \noverride      0.693446  0.363591  0.659200      0.578643  0.321711  1.000000   \nbalkan        0.539695  0.214328  0.278511      0.447542  0.206997  0.503358   \nleader        0.611492  0.494869  0.689173      0.575884  0.320150  0.772362   \nshortage      0.713446  0.268732  0.556721      0.501684  0.280925  0.755925   \n\n              balkan    leader  shortage  \neuropean    0.189467 -0.044983  0.206253  \ncouncil     0.282464 -0.012073  0.159523  \nregulation  0.304889  0.010416  0.194927  \ncommission  0.142213  0.131800  0.146521  \nparliament  0.237483 -0.000669  0.197068  \n...              ...       ...       ...  \npave        0.206997  0.320150  0.280925  \noverride    0.503358  0.772362  0.755925  \nbalkan      1.000000  0.529961  0.719155  \nleader      0.529961  1.000000  0.697482  \nshortage    0.719155  0.697482  1.000000  \n\n[3424 rows x 3424 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>european</th>\n      <th>council</th>\n      <th>regulation</th>\n      <th>commission</th>\n      <th>parliament</th>\n      <th>decision</th>\n      <th>committee</th>\n      <th>case</th>\n      <th>document</th>\n      <th>union</th>\n      <th>...</th>\n      <th>wastewater</th>\n      <th>salamander</th>\n      <th>supplier</th>\n      <th>donation</th>\n      <th>grandfathere</th>\n      <th>pave</th>\n      <th>override</th>\n      <th>balkan</th>\n      <th>leader</th>\n      <th>shortage</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>european</th>\n      <td>1.000000</td>\n      <td>0.731201</td>\n      <td>0.514220</td>\n      <td>0.548412</td>\n      <td>0.694949</td>\n      <td>0.404390</td>\n      <td>0.619209</td>\n      <td>-0.317524</td>\n      <td>0.457604</td>\n      <td>0.552975</td>\n      <td>...</td>\n      <td>-0.000420</td>\n      <td>0.181652</td>\n      <td>-0.056360</td>\n      <td>0.107092</td>\n      <td>0.003446</td>\n      <td>-0.158955</td>\n      <td>0.138907</td>\n      <td>0.189467</td>\n      <td>-0.044983</td>\n      <td>0.206253</td>\n    </tr>\n    <tr>\n      <th>council</th>\n      <td>0.731201</td>\n      <td>1.000000</td>\n      <td>0.638280</td>\n      <td>0.662799</td>\n      <td>0.672104</td>\n      <td>0.406194</td>\n      <td>0.496312</td>\n      <td>-0.354882</td>\n      <td>0.499966</td>\n      <td>0.492518</td>\n      <td>...</td>\n      <td>0.039089</td>\n      <td>0.060783</td>\n      <td>-0.065754</td>\n      <td>0.033837</td>\n      <td>-0.075030</td>\n      <td>-0.214734</td>\n      <td>0.108973</td>\n      <td>0.282464</td>\n      <td>-0.012073</td>\n      <td>0.159523</td>\n    </tr>\n    <tr>\n      <th>regulation</th>\n      <td>0.514220</td>\n      <td>0.638280</td>\n      <td>1.000000</td>\n      <td>0.441102</td>\n      <td>0.692700</td>\n      <td>0.674442</td>\n      <td>0.259965</td>\n      <td>-0.358772</td>\n      <td>0.333145</td>\n      <td>0.343419</td>\n      <td>...</td>\n      <td>0.077706</td>\n      <td>0.098298</td>\n      <td>-0.057382</td>\n      <td>-0.051784</td>\n      <td>-0.153557</td>\n      <td>-0.466323</td>\n      <td>0.136758</td>\n      <td>0.304889</td>\n      <td>0.010416</td>\n      <td>0.194927</td>\n    </tr>\n    <tr>\n      <th>commission</th>\n      <td>0.548412</td>\n      <td>0.662799</td>\n      <td>0.441102</td>\n      <td>1.000000</td>\n      <td>0.613464</td>\n      <td>0.402439</td>\n      <td>0.355325</td>\n      <td>-0.213437</td>\n      <td>0.672117</td>\n      <td>0.319866</td>\n      <td>...</td>\n      <td>0.159323</td>\n      <td>0.047444</td>\n      <td>0.083379</td>\n      <td>0.144360</td>\n      <td>-0.045840</td>\n      <td>-0.229820</td>\n      <td>0.158406</td>\n      <td>0.142213</td>\n      <td>0.131800</td>\n      <td>0.146521</td>\n    </tr>\n    <tr>\n      <th>parliament</th>\n      <td>0.694949</td>\n      <td>0.672104</td>\n      <td>0.692700</td>\n      <td>0.613464</td>\n      <td>1.000000</td>\n      <td>0.463719</td>\n      <td>0.500321</td>\n      <td>-0.339536</td>\n      <td>0.453496</td>\n      <td>0.541798</td>\n      <td>...</td>\n      <td>0.008435</td>\n      <td>0.023199</td>\n      <td>-0.115383</td>\n      <td>0.057549</td>\n      <td>-0.125723</td>\n      <td>-0.344435</td>\n      <td>0.134858</td>\n      <td>0.237483</td>\n      <td>-0.000669</td>\n      <td>0.197068</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>pave</th>\n      <td>-0.158955</td>\n      <td>-0.214734</td>\n      <td>-0.466323</td>\n      <td>-0.229820</td>\n      <td>-0.344435</td>\n      <td>-0.310094</td>\n      <td>0.240334</td>\n      <td>0.674720</td>\n      <td>-0.139408</td>\n      <td>-0.125918</td>\n      <td>...</td>\n      <td>0.264287</td>\n      <td>0.318491</td>\n      <td>0.013521</td>\n      <td>0.500347</td>\n      <td>0.537758</td>\n      <td>1.000000</td>\n      <td>0.321711</td>\n      <td>0.206997</td>\n      <td>0.320150</td>\n      <td>0.280925</td>\n    </tr>\n    <tr>\n      <th>override</th>\n      <td>0.138907</td>\n      <td>0.108973</td>\n      <td>0.136758</td>\n      <td>0.158406</td>\n      <td>0.134858</td>\n      <td>0.109988</td>\n      <td>0.389345</td>\n      <td>0.373732</td>\n      <td>0.284375</td>\n      <td>0.280294</td>\n      <td>...</td>\n      <td>0.720038</td>\n      <td>0.693446</td>\n      <td>0.363591</td>\n      <td>0.659200</td>\n      <td>0.578643</td>\n      <td>0.321711</td>\n      <td>1.000000</td>\n      <td>0.503358</td>\n      <td>0.772362</td>\n      <td>0.755925</td>\n    </tr>\n    <tr>\n      <th>balkan</th>\n      <td>0.189467</td>\n      <td>0.282464</td>\n      <td>0.304889</td>\n      <td>0.142213</td>\n      <td>0.237483</td>\n      <td>0.283080</td>\n      <td>0.243165</td>\n      <td>0.223026</td>\n      <td>0.102062</td>\n      <td>0.228592</td>\n      <td>...</td>\n      <td>0.595013</td>\n      <td>0.539695</td>\n      <td>0.214328</td>\n      <td>0.278511</td>\n      <td>0.447542</td>\n      <td>0.206997</td>\n      <td>0.503358</td>\n      <td>1.000000</td>\n      <td>0.529961</td>\n      <td>0.719155</td>\n    </tr>\n    <tr>\n      <th>leader</th>\n      <td>-0.044983</td>\n      <td>-0.012073</td>\n      <td>0.010416</td>\n      <td>0.131800</td>\n      <td>-0.000669</td>\n      <td>0.171448</td>\n      <td>0.150688</td>\n      <td>0.448404</td>\n      <td>0.178180</td>\n      <td>0.164615</td>\n      <td>...</td>\n      <td>0.867434</td>\n      <td>0.611492</td>\n      <td>0.494869</td>\n      <td>0.689173</td>\n      <td>0.575884</td>\n      <td>0.320150</td>\n      <td>0.772362</td>\n      <td>0.529961</td>\n      <td>1.000000</td>\n      <td>0.697482</td>\n    </tr>\n    <tr>\n      <th>shortage</th>\n      <td>0.206253</td>\n      <td>0.159523</td>\n      <td>0.194927</td>\n      <td>0.146521</td>\n      <td>0.197068</td>\n      <td>0.148615</td>\n      <td>0.254271</td>\n      <td>0.480956</td>\n      <td>0.243255</td>\n      <td>0.180428</td>\n      <td>...</td>\n      <td>0.687595</td>\n      <td>0.713446</td>\n      <td>0.268732</td>\n      <td>0.556721</td>\n      <td>0.501684</td>\n      <td>0.280925</td>\n      <td>0.755925</td>\n      <td>0.719155</td>\n      <td>0.697482</td>\n      <td>1.000000</td>\n    </tr>\n  </tbody>\n</table>\n<p>3424 rows × 3424 columns</p>\n</div>"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model2_cosine_similarity_matrix = get_similarity_matrix(model2_selected_pos_embeddings,\n",
    "                                                        model2_selected_pos,\n",
    "                                                        metric=cosine_similarity)\n",
    "model2_cosine_similarity_matrix"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "# % % time\n",
    "# model3_cosine_similarity_matrix = get_similarity_matrix(model3_language_model_pipeline.word2vec.wv.vectors[:100],\n",
    "#                                                         model3_language_model_pipeline.word2vec.wv.index_to_key[:100],\n",
    "#                                                         metric=cosine_similarity)\n",
    "# model3_cosine_similarity_matrix"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Manhattan similarity"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "# % % time\n",
    "# model1_manhattan_similarity_matrix = get_similarity_matrix(model1_language_model_pipeline.word2vec.wv.vectors[:100],\n",
    "#                                                            model1_language_model_pipeline.word2vec.wv.index_to_key[\n",
    "#                                                            :100],\n",
    "#                                                            metric=manhattan_similarity)\n",
    "# model1_manhattan_similarity_matrix"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "data": {
      "text/plain": "            european   council  regulation  commission  parliament  decision  \\\neuropean    1.000000  0.007373    0.005094    0.006096    0.006707  0.005137   \ncouncil     0.007373  1.000000    0.006138    0.007098    0.006350  0.005240   \nregulation  0.005094  0.006138    1.000000    0.005230    0.006254  0.006615   \ncommission  0.006096  0.007098    0.005230    1.000000    0.006083  0.005754   \nparliament  0.006707  0.006350    0.006254    0.006083    1.000000  0.005265   \n...              ...       ...         ...         ...         ...       ...   \npave        0.005270  0.005303    0.005026    0.006498    0.004989  0.005911   \noverride    0.005284  0.005320    0.005054    0.006528    0.005010  0.005935   \nbalkan      0.005289  0.005331    0.005061    0.006529    0.005017  0.005945   \nleader      0.005275  0.005321    0.005049    0.006539    0.005005  0.005942   \nshortage    0.005288  0.005326    0.005056    0.006530    0.005015  0.005937   \n\n            committee      case  document     union  ...  wastewater  \\\neuropean     0.005993  0.002886  0.004994  0.005782  ...    0.005280   \ncouncil      0.005257  0.002872  0.005226  0.005607  ...    0.005320   \nregulation   0.004046  0.002841  0.004230  0.004536  ...    0.005052   \ncommission   0.004947  0.003218  0.006467  0.005003  ...    0.006530   \nparliament   0.004983  0.002827  0.004794  0.005654  ...    0.005006   \n...               ...       ...       ...       ...  ...         ...   \npave         0.005058  0.004194  0.004976  0.005374  ...    0.320973   \noverride     0.005063  0.004182  0.004991  0.005394  ...    0.454482   \nbalkan       0.005060  0.004181  0.004983  0.005393  ...    0.393788   \nleader       0.005058  0.004193  0.004993  0.005395  ...    0.405444   \nshortage     0.005060  0.004187  0.004990  0.005390  ...    0.422398   \n\n            salamander  supplier  donation  grandfathere      pave  override  \\\neuropean      0.005289  0.005274  0.005282      0.005279  0.005270  0.005284   \ncouncil       0.005320  0.005312  0.005316      0.005312  0.005303  0.005320   \nregulation    0.005053  0.005049  0.005046      0.005044  0.005026  0.005054   \ncommission    0.006523  0.006520  0.006525      0.006512  0.006498  0.006528   \nparliament    0.005006  0.005004  0.005008      0.005001  0.004989  0.005010   \n...                ...       ...       ...           ...       ...       ...   \npave          0.337905  0.296603  0.371773      0.392443  1.000000  0.337010   \noverride      0.458793  0.375071  0.448611      0.444909  0.337010  1.000000   \nbalkan        0.380275  0.323187  0.335197      0.375362  0.305543  0.371704   \nleader        0.322692  0.304147  0.332309      0.320438  0.276014  0.357356   \nshortage      0.446703  0.343899  0.394403      0.394699  0.321604  0.477827   \n\n              balkan    leader  shortage  \neuropean    0.005289  0.005275  0.005288  \ncouncil     0.005331  0.005321  0.005326  \nregulation  0.005061  0.005049  0.005056  \ncommission  0.006529  0.006539  0.006530  \nparliament  0.005017  0.005005  0.005015  \n...              ...       ...       ...  \npave        0.305543  0.276014  0.321604  \noverride    0.371704  0.357356  0.477827  \nbalkan      1.000000  0.306189  0.430648  \nleader      0.306189  1.000000  0.343105  \nshortage    0.430648  0.343105  1.000000  \n\n[3424 rows x 3424 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>european</th>\n      <th>council</th>\n      <th>regulation</th>\n      <th>commission</th>\n      <th>parliament</th>\n      <th>decision</th>\n      <th>committee</th>\n      <th>case</th>\n      <th>document</th>\n      <th>union</th>\n      <th>...</th>\n      <th>wastewater</th>\n      <th>salamander</th>\n      <th>supplier</th>\n      <th>donation</th>\n      <th>grandfathere</th>\n      <th>pave</th>\n      <th>override</th>\n      <th>balkan</th>\n      <th>leader</th>\n      <th>shortage</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>european</th>\n      <td>1.000000</td>\n      <td>0.007373</td>\n      <td>0.005094</td>\n      <td>0.006096</td>\n      <td>0.006707</td>\n      <td>0.005137</td>\n      <td>0.005993</td>\n      <td>0.002886</td>\n      <td>0.004994</td>\n      <td>0.005782</td>\n      <td>...</td>\n      <td>0.005280</td>\n      <td>0.005289</td>\n      <td>0.005274</td>\n      <td>0.005282</td>\n      <td>0.005279</td>\n      <td>0.005270</td>\n      <td>0.005284</td>\n      <td>0.005289</td>\n      <td>0.005275</td>\n      <td>0.005288</td>\n    </tr>\n    <tr>\n      <th>council</th>\n      <td>0.007373</td>\n      <td>1.000000</td>\n      <td>0.006138</td>\n      <td>0.007098</td>\n      <td>0.006350</td>\n      <td>0.005240</td>\n      <td>0.005257</td>\n      <td>0.002872</td>\n      <td>0.005226</td>\n      <td>0.005607</td>\n      <td>...</td>\n      <td>0.005320</td>\n      <td>0.005320</td>\n      <td>0.005312</td>\n      <td>0.005316</td>\n      <td>0.005312</td>\n      <td>0.005303</td>\n      <td>0.005320</td>\n      <td>0.005331</td>\n      <td>0.005321</td>\n      <td>0.005326</td>\n    </tr>\n    <tr>\n      <th>regulation</th>\n      <td>0.005094</td>\n      <td>0.006138</td>\n      <td>1.000000</td>\n      <td>0.005230</td>\n      <td>0.006254</td>\n      <td>0.006615</td>\n      <td>0.004046</td>\n      <td>0.002841</td>\n      <td>0.004230</td>\n      <td>0.004536</td>\n      <td>...</td>\n      <td>0.005052</td>\n      <td>0.005053</td>\n      <td>0.005049</td>\n      <td>0.005046</td>\n      <td>0.005044</td>\n      <td>0.005026</td>\n      <td>0.005054</td>\n      <td>0.005061</td>\n      <td>0.005049</td>\n      <td>0.005056</td>\n    </tr>\n    <tr>\n      <th>commission</th>\n      <td>0.006096</td>\n      <td>0.007098</td>\n      <td>0.005230</td>\n      <td>1.000000</td>\n      <td>0.006083</td>\n      <td>0.005754</td>\n      <td>0.004947</td>\n      <td>0.003218</td>\n      <td>0.006467</td>\n      <td>0.005003</td>\n      <td>...</td>\n      <td>0.006530</td>\n      <td>0.006523</td>\n      <td>0.006520</td>\n      <td>0.006525</td>\n      <td>0.006512</td>\n      <td>0.006498</td>\n      <td>0.006528</td>\n      <td>0.006529</td>\n      <td>0.006539</td>\n      <td>0.006530</td>\n    </tr>\n    <tr>\n      <th>parliament</th>\n      <td>0.006707</td>\n      <td>0.006350</td>\n      <td>0.006254</td>\n      <td>0.006083</td>\n      <td>1.000000</td>\n      <td>0.005265</td>\n      <td>0.004983</td>\n      <td>0.002827</td>\n      <td>0.004794</td>\n      <td>0.005654</td>\n      <td>...</td>\n      <td>0.005006</td>\n      <td>0.005006</td>\n      <td>0.005004</td>\n      <td>0.005008</td>\n      <td>0.005001</td>\n      <td>0.004989</td>\n      <td>0.005010</td>\n      <td>0.005017</td>\n      <td>0.005005</td>\n      <td>0.005015</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>pave</th>\n      <td>0.005270</td>\n      <td>0.005303</td>\n      <td>0.005026</td>\n      <td>0.006498</td>\n      <td>0.004989</td>\n      <td>0.005911</td>\n      <td>0.005058</td>\n      <td>0.004194</td>\n      <td>0.004976</td>\n      <td>0.005374</td>\n      <td>...</td>\n      <td>0.320973</td>\n      <td>0.337905</td>\n      <td>0.296603</td>\n      <td>0.371773</td>\n      <td>0.392443</td>\n      <td>1.000000</td>\n      <td>0.337010</td>\n      <td>0.305543</td>\n      <td>0.276014</td>\n      <td>0.321604</td>\n    </tr>\n    <tr>\n      <th>override</th>\n      <td>0.005284</td>\n      <td>0.005320</td>\n      <td>0.005054</td>\n      <td>0.006528</td>\n      <td>0.005010</td>\n      <td>0.005935</td>\n      <td>0.005063</td>\n      <td>0.004182</td>\n      <td>0.004991</td>\n      <td>0.005394</td>\n      <td>...</td>\n      <td>0.454482</td>\n      <td>0.458793</td>\n      <td>0.375071</td>\n      <td>0.448611</td>\n      <td>0.444909</td>\n      <td>0.337010</td>\n      <td>1.000000</td>\n      <td>0.371704</td>\n      <td>0.357356</td>\n      <td>0.477827</td>\n    </tr>\n    <tr>\n      <th>balkan</th>\n      <td>0.005289</td>\n      <td>0.005331</td>\n      <td>0.005061</td>\n      <td>0.006529</td>\n      <td>0.005017</td>\n      <td>0.005945</td>\n      <td>0.005060</td>\n      <td>0.004181</td>\n      <td>0.004983</td>\n      <td>0.005393</td>\n      <td>...</td>\n      <td>0.393788</td>\n      <td>0.380275</td>\n      <td>0.323187</td>\n      <td>0.335197</td>\n      <td>0.375362</td>\n      <td>0.305543</td>\n      <td>0.371704</td>\n      <td>1.000000</td>\n      <td>0.306189</td>\n      <td>0.430648</td>\n    </tr>\n    <tr>\n      <th>leader</th>\n      <td>0.005275</td>\n      <td>0.005321</td>\n      <td>0.005049</td>\n      <td>0.006539</td>\n      <td>0.005005</td>\n      <td>0.005942</td>\n      <td>0.005058</td>\n      <td>0.004193</td>\n      <td>0.004993</td>\n      <td>0.005395</td>\n      <td>...</td>\n      <td>0.405444</td>\n      <td>0.322692</td>\n      <td>0.304147</td>\n      <td>0.332309</td>\n      <td>0.320438</td>\n      <td>0.276014</td>\n      <td>0.357356</td>\n      <td>0.306189</td>\n      <td>1.000000</td>\n      <td>0.343105</td>\n    </tr>\n    <tr>\n      <th>shortage</th>\n      <td>0.005288</td>\n      <td>0.005326</td>\n      <td>0.005056</td>\n      <td>0.006530</td>\n      <td>0.005015</td>\n      <td>0.005937</td>\n      <td>0.005060</td>\n      <td>0.004187</td>\n      <td>0.004990</td>\n      <td>0.005390</td>\n      <td>...</td>\n      <td>0.422398</td>\n      <td>0.446703</td>\n      <td>0.343899</td>\n      <td>0.394403</td>\n      <td>0.394699</td>\n      <td>0.321604</td>\n      <td>0.477827</td>\n      <td>0.430648</td>\n      <td>0.343105</td>\n      <td>1.000000</td>\n    </tr>\n  </tbody>\n</table>\n<p>3424 rows × 3424 columns</p>\n</div>"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2_manhattan_similarity_matrix = get_similarity_matrix(model2_selected_pos_embeddings,\n",
    "                                                           model2_selected_pos,\n",
    "                                                           metric=manhattan_similarity)\n",
    "model2_manhattan_similarity_matrix"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "# % % time\n",
    "# model3_manhattan_similarity_matrix = get_similarity_matrix(model3_language_model_pipeline.word2vec.wv.vectors[:100],\n",
    "#                                                            model3_language_model_pipeline.word2vec.wv.index_to_key[\n",
    "#                                                            :100],\n",
    "#                                                            metric=manhattan_similarity)\n",
    "# model3_manhattan_similarity_matrix"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [],
   "source": [
    "# def generate_graph(similarity_matrix: pd.DataFrame, graph: nx.Graph, root_word: str, top_words: int,\n",
    "#                    threshold:np.float64 = 0.8, deep_level: int = 0, max_deep_level: int = 2) -> nx.Graph:\n",
    "#     if deep_level > max_deep_level:\n",
    "#         return graph\n",
    "#     new_nodes = similarity_matrix[root_word].sort_values(ascending=False)[:top_words].index.to_list()\n",
    "#     new_nodes_weight = list(similarity_matrix[root_word].sort_values(ascending=False)[:top_words].values)\n",
    "#     for index in range(0, len(new_nodes)):\n",
    "#         if new_nodes_weight[index] >= threshold:\n",
    "#             graph.add_edge(root_word, new_nodes[index])\n",
    "#             generate_graph(similarity_matrix, graph, new_nodes[index], top_words + 1, threshold, deep_level+1, max_deep_level)\n",
    "#\n",
    "#     return graph\n",
    "\n",
    "def generate_graph(similarity_matrix: pd.DataFrame, graph: nx.Graph, root_word: str, top_words: int,\n",
    "                   threshold:np.float64 = 0.8, deep_level: int = 0, max_deep_level: int = 2) -> nx.Graph:\n",
    "    if deep_level > max_deep_level:\n",
    "        return graph\n",
    "    new_nodes = similarity_matrix[root_word].sort_values(ascending=False)[:top_words].index.to_list()\n",
    "    new_nodes_weight = list(similarity_matrix[root_word].sort_values(ascending=False)[:top_words].values)\n",
    "    for index in range(0, len(new_nodes)):\n",
    "        if new_nodes_weight[index] >= threshold:\n",
    "            # graph.add_edge(root_word, new_nodes[index])\n",
    "            # generate_graph(similarity_matrix, graph, new_nodes[index], top_words + 1, threshold, deep_level+1, max_deep_level)\n",
    "            pass\n",
    "    return graph"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "outputs": [],
   "source": [
    "from d3graph import d3graph, vec2adjmat\n",
    "\n",
    "G = nx.karate_club_graph()\n",
    "adjmat = nx.adjacency_matrix(G).todense()\n",
    "adjmat = pd.DataFrame(index=range(0,adjmat.shape[0]), data=adjmat, columns=range(0,adjmat.shape[0]))\n",
    "adjmat.iloc[3,4]=5\n",
    "adjmat.iloc[4,5]=6\n",
    "\n",
    "a = model2_cosine_similarity_matrix[['european', 'council', 'regulation', 'commission', 'parliament']].head()\n",
    "a.columns = a.columns.astype(str)\n",
    "a.index = a.index.astype(str)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'd3graph' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-1-d84229d6ee9d>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0md3graph\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0ma\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      2\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mNameError\u001B[0m: name 'd3graph' is not defined"
     ]
    }
   ],
   "source": [
    "d3graph(a)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Select key words as clusters to visualize the graph similarity between this words\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Steps for word embedding visualization:\n",
    "* detect and extract key words and most relevant words\n",
    "* train TSNE model\n",
    "* create a dataframe with the clusters, their words and their placement on the graph"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# model1_word_embeddings = select_words_and_embedding_clusters(model1_language_model_pipeline.word2vec.wv, key_words)\n",
    "# model2_word_embeddings = select_words_and_embedding_clusters(model2_language_model_pipeline.word2vec.wv, key_words)\n",
    "# model3_word_embeddings = select_words_and_embedding_clusters(model3_language_model_pipeline.word2vec.wv, key_words)\n",
    "#\n",
    "# model1_tsne_model = create_tsne_model(model1_word_embeddings[0])\n",
    "# model2_tsne_model = create_tsne_model(model2_word_embeddings[0])\n",
    "# model3_tsne_model = create_tsne_model(model3_word_embeddings[0])\n",
    "#\n",
    "# model1_word_embeddings_dataframe = create_word_clusters_matrix(key_words, model1_word_embeddings[1], model1_tsne_model)\n",
    "# model2_word_embeddings_dataframe = create_word_clusters_matrix(key_words, model2_word_embeddings[1], model2_tsne_model)\n",
    "# model3_word_embeddings_dataframe = create_word_clusters_matrix(key_words, model3_word_embeddings[1], model3_tsne_model)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Graph visualization for the first model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# model1_word_cluster_plot = px.scatter(model1_word_embeddings_dataframe,\n",
    "#                                       x='X', y='Y', color=model1_word_embeddings_dataframe.word_cluster,\n",
    "#                                       labels={'color': 'word'}, hover_data=[\"word\"])\n",
    "# model1_word_cluster_plot\n",
    "#"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Graph visualization for the second model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# model2_word_cluster_plot = px.scatter(model2_word_embeddings_dataframe,\n",
    "#                                       x='X', y='Y', color=model2_word_embeddings_dataframe.word_cluster,\n",
    "#                                       labels={'color': 'word'}, hover_data=[\"word\"])\n",
    "# model2_word_cluster_plot\n",
    "#"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Graph visualization for the third model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# model3_word_cluster_plot = px.scatter(model3_word_embeddings_dataframe,\n",
    "#                                       x='X', y='Y', color=model3_word_embeddings_dataframe.word_cluster,\n",
    "#                                       labels={'color': 'word'}, hover_data=[\"word\"])\n",
    "# model3_word_cluster_plot"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}