{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Word2vec model training\n",
    "#### Model training based on three datasets' text data:\n",
    "- M1: pwdb + eu_timeline  ( +  ireland_timeline )\n",
    "- M2: ds_eu_cellar\n",
    "- M3: M1+M2\n",
    "\n",
    "#### Extract NOUN and NOUN PHRASES from each text data\n",
    "#### Train the word2vec model with each dataset's textual data"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Import libraries"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Since the GPL-licensed package `unidecode` is not installed, using Python's `unicodedata` package which yields worse results.\n"
     ]
    }
   ],
   "source": [
    "# import sys\n",
    "# sys.path.append(\"/home/jovyan/work/sem-covid/\")\n",
    "# sys.path = list(set(sys.path))\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "\n",
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "import pandas as pd\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "from sem_covid.services.sc_wrangling.data_cleaning import clean_text_from_specific_characters, clean_fix_unicode, \\\n",
    "    clean_remove_currency_symbols, clean_remove_emails, clean_remove_urls\n",
    "\n",
    "from sem_covid.entrypoints.notebooks.topic_modeling.topic_modeling_wrangling.token_management import filter_stop_words, \\\n",
    "    select_pos, filter_stop_words_on_a_span_list\n",
    "\n",
    "from sem_covid.services.data_registry import Dataset"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Download datasets and extract textual data\n",
    "### Fetching the data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "outputs": [],
   "source": [
    "pwdb = Dataset.PWDB.fetch()\n",
    "eu_timeline = Dataset.EU_ACTION_TIMELINE_ENRICHED.fetch()\n",
    "ireland_timeline = Dataset.IRELAND_ACTION_TIMELINE_ENRICHED.fetch()\n",
    "eu_cellar = Dataset.EU_CELLAR_ENRICHED.fetch()\n",
    "\n",
    "pwdb.fillna(value=\"\", inplace=True)\n",
    "eu_timeline.fillna(value=\"\", inplace=True)\n",
    "ireland_timeline.fillna(value=\"\", inplace=True)\n",
    "eu_cellar.fillna(value=\"\", inplace=True)\n",
    "\n",
    "pwdb_document_corpus = pwdb['title'] + '. ' + \\\n",
    "                       pwdb['background_info_description'] + '. ' + \\\n",
    "                       pwdb['content_of_measure_description'] + '. ' + \\\n",
    "                       pwdb['use_of_measure_description'] + '. ' + \\\n",
    "                       pwdb['involvement_of_social_partners_description']\n",
    "\n",
    "eu_timeline_document_corpus = eu_timeline['title']\n",
    "\n",
    "ireland_timeline_document_corpus = ireland_timeline['title']\n",
    "\n",
    "eu_cellar_document_corpus = eu_cellar['title']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Data preprocessing\n",
    "- data cleanup\n",
    "- turn corpus into spacy document"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "def apply_cleaning_functions(document_corpus: pd.Series) -> pd.Series:\n",
    "    \"\"\"\n",
    "    This function receives the document and leads through cleaning steps\n",
    "    Args:\n",
    "        document_corpus: dataset document corpus\n",
    "\n",
    "    Returns: clean document corpus\n",
    "    \"\"\"\n",
    "    unused_characters = [\"\\\\r\", \">\", \"\\n\", \"\\\\\", \"<\", \"''\", \"%\", \"...\", \"\\'\", '\"', \"(\", \"\\n\", \"*\", \"1)\", \"2)\", \"3)\",\n",
    "                     \"[\", \"]\", \"-\", \"_\", \"\\r\"]\n",
    "\n",
    "    new_document_corpus = document_corpus.apply(clean_text_from_specific_characters, characters=unused_characters)\n",
    "    new_document_corpus = new_document_corpus.apply(clean_fix_unicode)\n",
    "    new_document_corpus = new_document_corpus.apply(clean_remove_urls)\n",
    "    new_document_corpus = new_document_corpus.apply(clean_remove_emails)\n",
    "    new_document_corpus = new_document_corpus.apply(clean_remove_currency_symbols)\n",
    "\n",
    "    return new_document_corpus"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "clean_pwdb_document = apply_cleaning_functions(pwdb_document_corpus)\n",
    "clean_eu_timeline_document = apply_cleaning_functions(eu_timeline_document_corpus)\n",
    "clean_ireland_timeline_document = apply_cleaning_functions(ireland_timeline_document_corpus)\n",
    "clean_eu_cellar_document = apply_cleaning_functions(eu_cellar_document_corpus)\n",
    "\n",
    "pwdb_spacy_corpus = clean_pwdb_document.apply(nlp)\n",
    "eu_timeline_spacy_corpus = clean_eu_timeline_document.apply(nlp)\n",
    "ireland_timeline_spacy_corpus = clean_ireland_timeline_document.apply(nlp)\n",
    "eu_cellar_spacy_corpus = clean_eu_cellar_document.apply(nlp)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Filter document tokens and select only NOUN and NOUN PHRASES"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [],
   "source": [
    "pwdb_noun_corpus = pwdb_spacy_corpus.apply(select_pos, pos=\"NOUN\")\n",
    "pwdb_noun_corpus = pwdb_noun_corpus.apply(lambda x: list(map(lambda docs: docs.lemma_, x)))\n",
    "\n",
    "eu_timeline_noun_corpus = eu_timeline_spacy_corpus.apply(select_pos, pos=\"NOUN\")\n",
    "eu_timeline_noun_corpus = eu_timeline_noun_corpus.apply(lambda x: list(map(lambda docs: docs.lemma_, x)))\n",
    "\n",
    "ireland_timeline_noun_corpus = ireland_timeline_spacy_corpus.apply(select_pos, pos=\"NOUN\")\n",
    "ireland_timeline_noun_corpus = ireland_timeline_noun_corpus.apply(lambda x: list(map(lambda docs: docs.lemma_, x)))\n",
    "\n",
    "eu_cellar_noun_corpus = eu_cellar_spacy_corpus.apply(select_pos, pos=\"NOUN\")\n",
    "eu_cellar_noun_corpus = eu_cellar_noun_corpus.apply(lambda x: list(map(lambda docs: docs.lemma_, x)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [],
   "source": [
    "pwdb_noun_phrase_corpus = pwdb_spacy_corpus.apply(lambda x: x.noun_chunks)\n",
    "pwdb_noun_phrase_corpus = pwdb_noun_phrase_corpus.apply(filter_stop_words_on_a_span_list)\n",
    "\n",
    "eu_timeline_noun_phrase_corpus = eu_timeline_spacy_corpus.apply(lambda x: x.noun_chunks)\n",
    "eu_timeline_noun_phrase_corpus = eu_timeline_noun_phrase_corpus.apply(filter_stop_words_on_a_span_list)\n",
    "\n",
    "ireland_timeline_noun_phrase_corpus = ireland_timeline_spacy_corpus.apply(lambda x: x.noun_chunks)\n",
    "ireland_timeline_noun_phrase_corpus = ireland_timeline_noun_phrase_corpus.apply(filter_stop_words_on_a_span_list)\n",
    "\n",
    "eu_cellar_noun_phrase_corpus = eu_cellar_spacy_corpus.apply(lambda x: x.noun_chunks)\n",
    "eu_cellar_noun_phrase_corpus = eu_cellar_noun_phrase_corpus.apply(filter_stop_words_on_a_span_list)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Train Word2vec model based on extracted NOUNS and NOUN PHRASES"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [
    {
     "data": {
      "text/plain": "(23096, 72200)"
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "WINDOW = 5\n",
    "MIN_COUNT = 10\n",
    "VECTOR_SIZE = 300\n",
    "EPOCHS = 50\n",
    "EU_TIMELINE_TOTAL_EXAMPLES = 171\n",
    "IRELAND_TIMELINE_TOTAL_EXAMPLES = 410\n",
    "EU_CELLAR_TOTAL_EXAMPLES = 2653\n",
    "\n",
    "m1_noun_word2vec = Word2Vec(sentences=pwdb_noun_corpus, window=WINDOW,\n",
    "                            min_count=MIN_COUNT, vector_size=VECTOR_SIZE)\n",
    "m1_noun_word2vec.train(eu_timeline_noun_corpus, total_examples=EU_TIMELINE_TOTAL_EXAMPLES, epochs=EPOCHS)\n",
    "m1_noun_word2vec.train(ireland_timeline_noun_corpus, total_examples=IRELAND_TIMELINE_TOTAL_EXAMPLES, epochs=EPOCHS)\n",
    "\n",
    "m1_noun_phrases_word2vec = Word2Vec(sentences=pwdb_noun_phrase_corpus, window=WINDOW,\n",
    "                                    min_count=MIN_COUNT, vector_size=VECTOR_SIZE)\n",
    "m1_noun_phrases_word2vec.train(eu_timeline_noun_phrase_corpus,\n",
    "                               total_examples=EU_TIMELINE_TOTAL_EXAMPLES, epochs=EPOCHS)\n",
    "m1_noun_phrases_word2vec.train(ireland_timeline_noun_phrase_corpus,\n",
    "                               total_examples=IRELAND_TIMELINE_TOTAL_EXAMPLES, epochs=EPOCHS)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "outputs": [],
   "source": [
    "m2_noun_word2vec = Word2Vec(sentences=eu_cellar_noun_corpus, window=WINDOW,\n",
    "                            min_count=MIN_COUNT, vector_size=VECTOR_SIZE)\n",
    "m2_noun_phrases_word2vec = Word2Vec(sentences=eu_cellar_noun_phrase_corpus,\n",
    "                                    window=WINDOW, min_count=MIN_COUNT, vector_size=VECTOR_SIZE)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "outputs": [
    {
     "data": {
      "text/plain": "(532854, 1293000)"
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m3_noun_word2vec = Word2Vec(sentences=pwdb_noun_corpus, window=WINDOW,\n",
    "                            min_count=MIN_COUNT, vector_size=VECTOR_SIZE)\n",
    "m3_noun_word2vec.train(eu_timeline_noun_corpus, total_examples=EU_TIMELINE_TOTAL_EXAMPLES, epochs=EPOCHS)\n",
    "m3_noun_word2vec.train(ireland_timeline_noun_corpus, total_examples=IRELAND_TIMELINE_TOTAL_EXAMPLES, epochs=EPOCHS)\n",
    "m3_noun_word2vec.train(eu_cellar_noun_corpus, total_examples=EU_CELLAR_TOTAL_EXAMPLES, epochs=EPOCHS)\n",
    "\n",
    "\n",
    "m3_noun_phrases_word2vec = Word2Vec(sentences=pwdb_noun_phrase_corpus, window=WINDOW,\n",
    "                                    min_count=MIN_COUNT, vector_size=VECTOR_SIZE)\n",
    "m3_noun_phrases_word2vec.train(eu_timeline_noun_phrase_corpus, total_examples=EU_TIMELINE_TOTAL_EXAMPLES, epochs=EPOCHS)\n",
    "m3_noun_phrases_word2vec.train(ireland_timeline_noun_phrase_corpus,\n",
    "                               total_examples=IRELAND_TIMELINE_TOTAL_EXAMPLES, epochs=EPOCHS)\n",
    "m3_noun_phrases_word2vec.train(eu_cellar_noun_phrase_corpus, total_examples=EU_CELLAR_TOTAL_EXAMPLES, epochs=EPOCHS)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}