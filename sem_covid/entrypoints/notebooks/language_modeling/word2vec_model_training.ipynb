{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Word2vec model training\n",
    "#### Model training based on three datasets' text data:\n",
    "- M1: pwdb + eu_timeline  ( +  ireland_timeline )\n",
    "- M2: ds_eu_cellar\n",
    "- M3: M1+M2\n",
    "\n",
    "#### Extract NOUN and NOUN PHRASES from each text data\n",
    "#### Train the word2vec model with each dataset's textual data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Import libraries"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Since the GPL-licensed package `unidecode` is not installed, using Python's `unicodedata` package which yields worse results.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"/home/jovyan/work/sem-covid/\")\n",
    "sys.path = list(set(sys.path))\n",
    "\n",
    "import os\n",
    "\n",
    "os.getcwd()\n",
    "os.chdir('/home/jovyan/work/sem-covid/')\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from sem_covid.services.store_registry import store_registry\n",
    "from sem_covid.services.language_model_execution_steps import LanguageModelExecutionSteps\n",
    "from sem_covid.entrypoints.notebooks.language_modeling.language_model_tools.graph_handling import (\n",
    "    create_graph_for_language_model_key_words)\n",
    "from typing import List\n",
    "import time"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# economic\n",
    "## Define constants"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "DEFAULT_TEXTUAL_CLASS = ['Title', 'Content']\n",
    "\n",
    "PWDB_TEXTUAL_CLASS = ['title', 'background_info_description', 'content_of_measure_description',\n",
    "                      'country', 'category', 'subcategory', 'target_groups']\n",
    "\n",
    "EU_CELLAR_TEXTUAL_CLASS = ['title', 'content', 'eurovoc_concept_labels', 'subject_matter_labels',\n",
    "                           'directory_codes_labels']\n",
    "\n",
    "IRELAND_ACTION_TIMELINE_CLASS = ['title', 'content', 'keyword']\n",
    "\n",
    "EU_ACTION_TIMELINE_CLASS = ['abstract', 'title', 'topics', 'detail_content']\n",
    "\n",
    "KEY_WORDS_FOR_ALL_MODELS = [\"eu\", \"national\", \"work\", \"aid\", \"coronavirus\", \"covid19\", \"measures\",\n",
    "                            \"vaccine\", \"minister\", \"government\", \"organisations\",\n",
    "                            \"agreement\", \"unemployment\", \"insurance\", \"reorientation\", \"economy\",\n",
    "                            \"economic\", \"innovation\", \"research\", \"development\", \"risk\", \"transport\"]\n",
    "\n",
    "COUNTRIES = ['austria', 'belgium', 'bulgaria', 'croatia', 'cyprus', 'czechia', 'denmark', 'estonia',\n",
    "             'european_union', 'finland', 'france', 'germany', 'greece', 'hungary', 'ireland', 'italy',\n",
    "             'latvia', 'lithuania', 'luxembourg', 'malta', 'netherlands', 'norway', 'poland', 'portugal',\n",
    "             'romania', 'slovakia', 'slovenia', 'spain', 'sweden', 'united_kingdom']\n",
    "\n",
    "CATEGORY = ['retention', 'workplace', 'labour', 'recovery', 'adaptation',\n",
    "            'protection', 'essential', 'business_continuity',\n",
    "            'services', 'social', 'market']\n",
    "\n",
    "SUBCATEGORY = ['safety', 'arrangements', 'health', 'spending', 'working', 'support', 'occupational',\n",
    "               'stimulus_packages', 'access', 'time', 'finance', 'remote', 'flexibility',\n",
    "               'essential_services', 'remuneration']\n",
    "\n",
    "TARGET_GROUPS_L1 = ['businesses', 'workers', 'citizens']\n",
    "\n",
    "TARGET_GROUPS_L2 = ['company', 'older', 'people', 'female', 'aged', 'corporations',\n",
    "                    'single', 'person', 'forms', 'smes', 'ups', 'single_parents',\n",
    "                    'citizens', 'professions', 'parents', 'groups', 'youth',\n",
    "                    'sector', 'women', 'unemployed', 'care', 'facilities', 'standard',\n",
    "                    'specific', 'contractors', 'children', 'border', 'refugees',\n",
    "                    'minors', 'platform', 'employment', 'seasonal', 'disabled', 'migrants',\n",
    "                    'risk_group', 'commuters']\n",
    "\n",
    "FUNDING = ['companies', 'national_funds', 'employer', 'funds', 'european_funds', 'no_special_funding_required',\n",
    "           'regional_funds', 'local_funds', 'employers_organization', 'employees']\n",
    "\n",
    "WORDS_PACK1 = {'category': CATEGORY,\n",
    "               'subcategory': SUBCATEGORY,\n",
    "               'countries': COUNTRIES,\n",
    "               'target_groups_l1': TARGET_GROUPS_L1,\n",
    "               'target_groups_l2': TARGET_GROUPS_L2,\n",
    "               'funding': FUNDING}\n",
    "\n",
    "WORDS_PACK2 = {'keywords': KEY_WORDS_FOR_ALL_MODELS}\n",
    "\n",
    "MODEL_WORDS_PACKS = (WORDS_PACK1, WORDS_PACK1, WORDS_PACK2)\n",
    "\n",
    "\n",
    "MODEL_NAMES = ('model1', 'model2', 'model3')\n",
    "\n",
    "\n",
    "FILE_NAMES = ('model1_language_model.model',\n",
    "              'model2_language_model.model',\n",
    "              'model3_language_model.model'\n",
    "              )\n",
    "\n",
    "SIMILARITY_MATRIX_BUCKET_NAME = 'semantic-similarity-matrices'\n",
    "\n",
    "COSINE_SIMILARITY_MATRICES = ('model1_cosine_matrix.pkl',\n",
    "                              'model2_cosine_matrix.pkl',\n",
    "                              'model3_cosine_matrix.pkl'\n",
    "                              )"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Data preprocessing\n",
    "- data cleanup\n",
    "- turn corpus into spacy document\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Experiment Nr#1 language model based on:\n",
    "- PWDB\n",
    "- eu-timeline\n",
    "- ireland-timeline\n",
    "\n",
    "## Experiment Nr#2 language model based on:\n",
    "- eu-cellar\n",
    "\n",
    "## Experiment Nr#3 language model based on:\n",
    "- PWDB\n",
    "- eu-timeline\n",
    "- ireland-timeline\n",
    "- eu-cellar\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (4126 of 4126) |####################| Elapsed Time: 0:00:00 Time:  0:00:00\n"
     ]
    }
   ],
   "source": [
    "ds_unified = store_registry.es_index_store().get_dataframe('ds_unified_datasets')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "model1_df = ds_unified.query('Document_source != \"eu_cellar\"')\n",
    "model2_df = ds_unified.query('Document_source == \"eu_cellar\"')\n",
    "model3_df = ds_unified"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "MODEL_DATASET_SOURCES_CONFIGS = (\n",
    "    [\n",
    "        (model1_df, DEFAULT_TEXTUAL_CLASS),\n",
    "    ],\n",
    "    [\n",
    "        (model2_df, DEFAULT_TEXTUAL_CLASS),\n",
    "    ],\n",
    "    [\n",
    "        (model3_df, DEFAULT_TEXTUAL_CLASS),\n",
    "    ]\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Generate D3 Graphs"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Cosine similarity graph"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "def plot_graphs(pipeline: LanguageModelExecutionSteps, model_name: str, model_file_name: str,\n",
    "                threshold: np.float64, word_graph_configs: dict, normalize_func) -> None:\n",
    "    \"\"\"\n",
    "        steps of generating d3 graph, calling the similarity matrix from minio and normalizing it.\n",
    "    Args:\n",
    "        pipeline: Pipeline of language model execution stems\n",
    "        model_name: the name of the model\n",
    "        model_file_name: word2vec file name from MinIO\n",
    "        threshold: the minimum of similarity number\n",
    "        word_graph_configs: dictionary of key words\n",
    "        normalize_func: function of similarity normalization\n",
    "    \"\"\"\n",
    "    model_cosine_matrix = store_registry.minio_feature_store(SIMILARITY_MATRIX_BUCKET_NAME).get_features(\n",
    "        model_file_name)\n",
    "    model_cosine_matrix = model_cosine_matrix.applymap(normalize_func)\n",
    "    for key in word_graph_configs.keys():\n",
    "        create_graph_for_language_model_key_words(model_cosine_matrix,\n",
    "                                                  pipeline.filter_language_model_words().select_key_words(\n",
    "                                                      key_words=word_graph_configs[key]),\n",
    "                                                  model_name=model_name,\n",
    "                                                  metric_threshold=threshold, column_name=key)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "def execute_language_model_pipeline(model_file_name: str,\n",
    "                                    model_name: str,\n",
    "                                    model_dataset_sources_config: List[tuple],\n",
    "                                    #model_words_pack: dict,\n",
    "                                    #cosine_similarity_matrix: str\n",
    "                                    ):\n",
    "    start = time.time()\n",
    "    print(f'Start execution for {model_name}:')\n",
    "    model_execution_steps = LanguageModelExecutionSteps(language_model_file_name=model_file_name,\n",
    "                                                        model_name=model_name)\n",
    "    model_execution_steps.train_language_model(model_dataset_sources_config)\n",
    "    model_execution_steps.train_similarity_matrices()\n",
    "    # plot_graphs(pipeline=model_execution_steps,\n",
    "    #             model_name=model_name,\n",
    "    #             model_file_name=cosine_similarity_matrix,\n",
    "    #             threshold=0.6,\n",
    "    #             word_graph_configs=model_words_pack,\n",
    "    #             normalize_func=lambda x: 1 - x)\n",
    "    del model_execution_steps\n",
    "    end = time.time()\n",
    "    print(f'Execution finish for {model_name} in:')\n",
    "    print(round((end - start), 4), 'seconds')\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start execution for model2:\n",
      "Start computing similarity matrix.\n"
     ]
    }
   ],
   "source": [
    "for model_file_name, model_name, model_dataset_sources_config in zip(\n",
    "        FILE_NAMES[1:], MODEL_NAMES[1:],\n",
    "        MODEL_DATASET_SOURCES_CONFIGS[1:],\n",
    "        #MODEL_WORDS_PACKS,\n",
    "        #COSINE_SIMILARITY_MATRICES\n",
    "    ):\n",
    "    execute_language_model_pipeline(model_file_name=model_file_name,\n",
    "                                    model_name=model_name,\n",
    "                                    model_dataset_sources_config=model_dataset_sources_config,\n",
    "                                    #model_words_pack=model_words_pack,\n",
    "                                    #cosine_similarity_matrix=cosine_similarity_matrix\n",
    "                                    )\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n"
     ]
    }
   ],
   "source": [
    "print('12')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from gensim.models import WordEmbeddingSimilarityIndex\n",
    "\n",
    "WordEmbeddingSimilarityIndex"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}