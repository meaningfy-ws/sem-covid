{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Word2vec model training\n",
    "#### Model training based on three datasets' text data:\n",
    "- M1: pwdb + eu_timeline  ( +  ireland_timeline )\n",
    "- M2: ds_eu_cellar\n",
    "- M3: M1+M2\n",
    "\n",
    "#### Extract NOUN and NOUN PHRASES from each text data\n",
    "#### Train the word2vec model with each dataset's textual data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Import libraries"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/home/jovyan/work/sem-covid/\")\n",
    "sys.path = list(set(sys.path))\n",
    "\n",
    "import os\n",
    "os.getcwd()\n",
    "os.chdir('/home/jovyan/work/sem-covid/')\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sem_covid.services.data_registry import Dataset\n",
    "from sem_covid.services.store_registry import store_registry\n",
    "from sem_covid.services.language_model_execution_steps import LanguageModelExecutionSteps\n",
    "from sem_covid.entrypoints.notebooks.language_modeling.language_model_tools.graph_handling import create_graph_for_language_model_key_words"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# economic\n",
    "## Define constants"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "PWDB_TEXTUAL_CLASS = ['title', 'background_info_description', 'content_of_measure_description',\n",
    "                      'use_of_measure_description', 'involvement_of_social_partners_description']\n",
    "\n",
    "DEFAULT_TEXTUAL_COLUMN = ['title']\n",
    "\n",
    "KEY_WORDS_FOR_ALL_MODELS =  [\"eu\", \"national\", \"work\", \"aid\", \"coronavirus\", \"covid19\", \"measures\",\n",
    "                             \"vaccine\", \"minister\", \"government\", \"organisations\",\n",
    "                             \"agreement\", \"unemployment\", \"insurance\", \"reorientation\", \"economy\",\n",
    "                             \"economic\", \"innovation\", \"research\", \"development\", \"risk\", \"transport\"]\n",
    "\n",
    "COUNTRIES = ['austria', 'belgium', 'bulgaria', 'croatia', 'cyprus', 'czechia', 'denmark', 'estonia',\n",
    "             'european_union', 'finland', 'france', 'germany', 'greece', 'hungary', 'ireland', 'italy',\n",
    "             'latvia', 'lithuania', 'luxembourg', 'malta', 'netherlands', 'norway', 'poland', 'portugal',\n",
    "             'romania', 'slovakia', 'slovenia', 'spain', 'sweden', 'united_kingdom']\n",
    "\n",
    "CATEGORY = ['retention', 'workplace', 'labour', 'recovery', 'adaptation',\n",
    "            'protection', 'essential', 'business_continuity',\n",
    "            'services', 'social', 'market']\n",
    "\n",
    "SUBCATEGORY = ['safety', 'arrangements', 'health', 'spending', 'working', 'support', 'occupational',\n",
    "               'stimulus_packages', 'access', 'time', 'finance', 'remote', 'flexibility',\n",
    "               'essential_services', 'remuneration']\n",
    "\n",
    "TARGET_GROUPS_L1 = ['businesses', 'workers', 'citizens']\n",
    "\n",
    "TARGET_GROUPS_L2 = ['company', 'older', 'people', 'female', 'aged', 'corporations',\n",
    "                    'single', 'person', 'forms', 'smes', 'ups', 'single_parents',\n",
    "                    'citizens', 'professions', 'parents', 'groups', 'youth',\n",
    "                    'sector', 'women', 'unemployed', 'care', 'facilities', 'standard',\n",
    "                    'specific', 'contractors', 'children', 'border', 'refugees',\n",
    "                    'minors', 'platform', 'employment', 'seasonal', 'disabled', 'migrants',\n",
    "                    'risk_group', 'commuters']\n",
    "\n",
    "FUNDING = ['companies', 'national_funds', 'employer', 'funds', 'european_funds', 'no_special_funding_required',\n",
    "           'regional_funds', 'local_funds', 'employers_organization', 'employees']\n",
    "\n",
    "\n",
    "\n",
    "MODEL1_AND_2_WORDS = {'category': CATEGORY,\n",
    "                        'subcategory': SUBCATEGORY,\n",
    "                        'countries': COUNTRIES,\n",
    "                        'target_groups_l1': TARGET_GROUPS_L1,\n",
    "                        'target_groups_l2': TARGET_GROUPS_L2,\n",
    "                        'funding': FUNDING}\n",
    "\n",
    "MODEL3_WORDS = {'keywords': KEY_WORDS_FOR_ALL_MODELS}\n",
    "\n",
    "NR1_MODEL_NAME = 'model1'\n",
    "NR2_MODEL_NAME = 'model2'\n",
    "NR3_MODEL_NAME = 'model3'\n",
    "\n",
    "MODEL1_FILE_NAME = 'model1_language_model.model'\n",
    "MODEL2_FILE_NAME = 'model2_language_model.model'\n",
    "MODEL3_FILE_NAME = 'model3_language_model.model'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Data preprocessing\n",
    "- data cleanup\n",
    "- turn corpus into spacy document\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "def plot_graphs(pipeline: LanguageModelExecutionSteps, model_name: str, model_file_name: str,\n",
    "                threshold: np.float64, word_graph_configs: dict, normalize_func) -> None:\n",
    "    \"\"\"\n",
    "        steps of generating d3 graph, calling the similarity matrix from minio and normalizing it.\n",
    "    Args:\n",
    "        pipeline: Pipeline of language model execution stems\n",
    "        model_name: the name of the model\n",
    "        model_file_name: word2vec file name from MinIO\n",
    "        threshold: the minimum of similarity number\n",
    "        word_graph_configs: dictionary of key words\n",
    "        normalize_func: function of similarity normalization\n",
    "    \"\"\"\n",
    "    model_cosine_matrix = store_registry.minio_object_store('semantic-similarity-matrices').get_object(model_file_name)\n",
    "    for key in word_graph_configs.keys():\n",
    "        create_graph_for_language_model_key_words(pd.read_json(model_cosine_matrix).applymap(normalize_func),\n",
    "                                                  pipeline.filter_language_model_words().select_key_words(key_words=word_graph_configs[key]),\n",
    "                                                  model_name=model_name,\n",
    "                                                  metric_threshold=threshold, column_name=key)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Experiment Nr#1 language model based on:\n",
    "- PWDB\n",
    "- eu-timeline\n",
    "- ireland-timeline\n",
    "\n",
    "## Experiment Nr#2 language model based on:\n",
    "- eu-cellar\n",
    "\n",
    "## Experiment Nr#3 language model based on:\n",
    "- PWDB\n",
    "- eu-timeline\n",
    "- ireland-timeline\n",
    "- eu-cellar\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "model1_dataset_sources_config = [\n",
    "    (Dataset.PWDB, PWDB_TEXTUAL_CLASS),\n",
    "    (Dataset.EU_ACTION_TIMELINE, DEFAULT_TEXTUAL_COLUMN),\n",
    "    (Dataset.IRELAND_ACTION_TIMELINE, DEFAULT_TEXTUAL_COLUMN)\n",
    "]\n",
    "\n",
    "model2_dataset_sources_config = [\n",
    "    (Dataset.EU_CELLAR_ENRICHED, DEFAULT_TEXTUAL_COLUMN),\n",
    "]\n",
    "\n",
    "model3_dataset_sources_config = [\n",
    "    (Dataset.PWDB, PWDB_TEXTUAL_CLASS),\n",
    "    (Dataset.EU_ACTION_TIMELINE, DEFAULT_TEXTUAL_COLUMN),\n",
    "    (Dataset.EU_CELLAR_ENRICHED, DEFAULT_TEXTUAL_COLUMN),\n",
    "    (Dataset.IRELAND_ACTION_TIMELINE, DEFAULT_TEXTUAL_COLUMN)\n",
    "]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "model1_execution_steps = LanguageModelExecutionSteps(language_model_file_name=MODEL1_FILE_NAME, model_name=NR1_MODEL_NAME)\n",
    "# model1_execution_steps.train_language_model(model1_dataset_sources_config)\n",
    "# model1_execution_steps.train_similarity_matrices()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "model2_execution_steps = LanguageModelExecutionSteps(language_model_file_name=MODEL2_FILE_NAME, model_name=NR2_MODEL_NAME)\n",
    "model2_execution_steps.train_language_model(model2_dataset_sources_config)\n",
    "# model2_execution_steps.train_similarity_matrices()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (1288 of 1288) |####################| Elapsed Time: 0:00:00 Time:  0:00:00\n",
      "100% (210 of 210) |######################| Elapsed Time: 0:00:00 Time:  0:00:00\n",
      "100% (1859 of 1859) |####################| Elapsed Time: 0:00:00 Time:  0:00:00\n"
     ]
    }
   ],
   "source": [
    "model3_execution_steps = LanguageModelExecutionSteps(language_model_file_name=MODEL3_FILE_NAME, model_name=NR3_MODEL_NAME)\n",
    "model3_execution_steps.train_language_model(model3_dataset_sources_config)\n",
    "# model3_execution_steps.train_similarity_matrices()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Generate D3 Graphs"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Cosine similarity graph"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print('start')\n",
    "plot_graphs(pipeline=model1_execution_steps,\n",
    "            model_name=NR1_MODEL_NAME,\n",
    "            model_file_name='model1_cosine_matrix.json',\n",
    "            threshold=0.6,\n",
    "            word_graph_configs=MODEL1_AND_2_WORDS,\n",
    "            normalize_func=lambda x: 1 - x)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start\n",
      "Writing /home/jovyan/work/sem-covid/docs/word-similarity-web/model2_graphs/category/recovery.html\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'recovery'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "\u001B[0;32m/tmp/ipykernel_24397/1637227037.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m'start'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 2\u001B[0;31m plot_graphs(pipeline=model2_execution_steps,\n\u001B[0m\u001B[1;32m      3\u001B[0m             \u001B[0mmodel_name\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mNR2_MODEL_NAME\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      4\u001B[0m             \u001B[0mmodel_file_name\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m'model2_cosine_matrix.json'\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      5\u001B[0m             \u001B[0mthreshold\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m0.6\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/tmp/ipykernel_24397/554509486.py\u001B[0m in \u001B[0;36mplot_graphs\u001B[0;34m(pipeline, model_name, model_file_name, threshold, word_graph_configs, normalize_func)\u001B[0m\n\u001B[1;32m     13\u001B[0m     \u001B[0mmodel_cosine_matrix\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mstore_registry\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mminio_object_store\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m'semantic-similarity-matrices'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mget_object\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmodel_file_name\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     14\u001B[0m     \u001B[0;32mfor\u001B[0m \u001B[0mkey\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mword_graph_configs\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mkeys\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 15\u001B[0;31m         create_graph_for_language_model_key_words(pd.read_json(model_cosine_matrix).applymap(normalize_func),\n\u001B[0m\u001B[1;32m     16\u001B[0m                                                   \u001B[0mpipeline\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfilter_language_model_words\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mselect_key_words\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mkey_words\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mword_graph_configs\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mkey\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     17\u001B[0m                                                   \u001B[0mmodel_name\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mmodel_name\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/work/sem-covid/sem_covid/entrypoints/notebooks/language_modeling/language_model_tools/graph_handling.py\u001B[0m in \u001B[0;36mcreate_graph_for_language_model_key_words\u001B[0;34m(similarity_matrix, language_model_words, model_name, column_name, metric_threshold)\u001B[0m\n\u001B[1;32m     67\u001B[0m         network_adjacency_matrix = pd.DataFrame(data=nx.adjacency_matrix(graph).todense(),\n\u001B[1;32m     68\u001B[0m                                                 index=graph.nodes(), columns=graph.nodes())\n\u001B[0;32m---> 69\u001B[0;31m         \u001B[0mnode_color_list\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0mdeep_map\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mnode\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;32mfor\u001B[0m \u001B[0mnode\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mgraph\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mnodes\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     70\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     71\u001B[0m         d3graph(network_adjacency_matrix, savepath=graph_folder_path, savename=language_model_words[index],\n",
      "\u001B[0;32m~/work/sem-covid/sem_covid/entrypoints/notebooks/language_modeling/language_model_tools/graph_handling.py\u001B[0m in \u001B[0;36m<listcomp>\u001B[0;34m(.0)\u001B[0m\n\u001B[1;32m     67\u001B[0m         network_adjacency_matrix = pd.DataFrame(data=nx.adjacency_matrix(graph).todense(),\n\u001B[1;32m     68\u001B[0m                                                 index=graph.nodes(), columns=graph.nodes())\n\u001B[0;32m---> 69\u001B[0;31m         \u001B[0mnode_color_list\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0mdeep_map\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mnode\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;32mfor\u001B[0m \u001B[0mnode\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mgraph\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mnodes\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     70\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     71\u001B[0m         d3graph(network_adjacency_matrix, savepath=graph_folder_path, savename=language_model_words[index],\n",
      "\u001B[0;31mKeyError\u001B[0m: 'recovery'"
     ]
    }
   ],
   "source": [
    "print('start')\n",
    "plot_graphs(pipeline=model2_execution_steps,\n",
    "            model_name=NR2_MODEL_NAME,\n",
    "            model_file_name='model2_cosine_matrix.json',\n",
    "            threshold=0.6,\n",
    "            word_graph_configs=MODEL1_AND_2_WORDS,\n",
    "            normalize_func=lambda x: 1 - x)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'plot_graphs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[0;32m/tmp/ipykernel_24343/977516874.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m'start'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 2\u001B[0;31m plot_graphs(pipeline=model3_execution_steps,\n\u001B[0m\u001B[1;32m      3\u001B[0m             \u001B[0mmodel_name\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mNR3_MODEL_NAME\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      4\u001B[0m             \u001B[0mmodel_file_name\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m'model3_cosine_matrix.json'\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      5\u001B[0m             \u001B[0mthreshold\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m0.6\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mNameError\u001B[0m: name 'plot_graphs' is not defined"
     ]
    }
   ],
   "source": [
    "print('start')\n",
    "plot_graphs(pipeline=model3_execution_steps,\n",
    "            model_name=NR3_MODEL_NAME,\n",
    "            model_file_name='model3_cosine_matrix.json',\n",
    "            threshold=0.6,\n",
    "            word_graph_configs=MODEL3_WORDS,\n",
    "            normalize_func=lambda x: 1 - x)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}