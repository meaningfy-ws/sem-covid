{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic modeling on eurlex textual data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/home/jovyan/work/sem-covid/\")\n",
    "sys.path = list(set(sys.path))\n",
    "\n",
    "import os\n",
    "os.getcwd()\n",
    "os.chdir('/home/jovyan/work/sem-covid/')\n",
    "\n",
    "import numpy as np\n",
    "np.random.seed(42)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "\n",
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "import gensim\n",
    "import pandas as pd\n",
    "import pyLDAvis.gensim_models\n",
    "import matplotlib.colors as mcolors\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "from bokeh.io import output_notebook\n",
    "from bokeh.plotting import figure, show\n",
    "from bokeh.models import ColumnDataSource\n",
    "\n",
    "from gensim.models import LdaModel, LsiModel\n",
    "from sem_covid.entrypoints.notebooks.topic_modeling.topic_modeling_wrangling.topic_visualizer import generate_wordcloud\n",
    "from sem_covid.services.data_registry import Dataset\n",
    "from sem_covid.services.sc_wrangling.data_cleaning import clean_text_from_specific_characters, clean_fix_unicode, \\\n",
    "    clean_remove_currency_symbols, clean_remove_emails, clean_remove_urls\n",
    "from sem_covid.entrypoints.notebooks.topic_modeling.topic_modeling_wrangling.token_management import filter_stop_words,\\\n",
    "    filter_pos, filter_stop_words_on_a_span_list, select_pos, spacy_stop_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fetching data from document store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "eurlex = Dataset.EU_CELLAR.fetch()\n",
    "\n",
    "eurlex.fillna(value=\"\", inplace=True)\n",
    "\n",
    "document_corpus = eurlex['title'].map(str) + '. ' + \\\n",
    "                  eurlex['content'].map(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Data preprocessing\n",
    "\n",
    "- data cleanup\n",
    "- turn corpus into spacy Docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "unused_characters = [\"\\\\r\", \">\", \"\\n\", \"\\\\\", \"<\", \"''\", \"%\", \"...\", \"\\'\", '\"', \"(\", \"\\n\", \"*\", \"1)\", \"2)\", \"3)\",\n",
    "                     \"[\", \"]\", \"-\", \"_\", \"\\r\"]\n",
    "\n",
    "document_corpus = document_corpus.apply(clean_text_from_specific_characters, characters=unused_characters)\n",
    "document_corpus = document_corpus.apply(clean_fix_unicode)\n",
    "document_corpus = document_corpus.apply(clean_remove_urls)\n",
    "document_corpus = document_corpus.apply(clean_remove_emails)\n",
    "document_corpus = document_corpus.apply(clean_remove_currency_symbols)\n",
    "nlp.max_length = 1500000\n",
    "spacy_corpus = document_corpus.apply(nlp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Preparing few corpora\n",
    "\n",
    "Filter document tokens. Select only the needed/interesting tokens for Topic modeling:\n",
    "   - all words\n",
    "   - nouns\n",
    "   - verbs\n",
    "   - noun phrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "word_corpus = spacy_corpus.apply(filter_stop_words, stop_words=spacy_stop_words)\n",
    "word_corpus = word_corpus.apply(filter_pos, pos=\"PUNCT\")\n",
    "word_corpus = word_corpus.apply(lambda x: list(map(lambda docs: docs.lemma_,x)))\n",
    "\n",
    "generate_wordcloud(\" \".join( [\" \".join(doc) for doc in word_corpus]) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "noun_corpus = spacy_corpus.apply(select_pos, pos=\"NOUN\")\n",
    "noun_corpus = noun_corpus.apply(lambda x: list(map(lambda docs: docs.lemma_,x)))\n",
    "\n",
    "generate_wordcloud(\" \".join( [\" \".join(doc) for doc in noun_corpus]) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "verb_corpus = spacy_corpus.apply(select_pos, pos=\"VERB\")\n",
    "verb_corpus = verb_corpus.apply(filter_stop_words)\n",
    "verb_corpus = verb_corpus.apply(lambda x: list(map(lambda docs: docs.lemma_,x)))\n",
    "\n",
    "generate_wordcloud(\" \".join( [\" \".join(doc) for doc in verb_corpus]) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "noun_phrase_corpus = spacy_corpus.apply(lambda x: x.noun_chunks)\n",
    "noun_phrase_corpus = noun_phrase_corpus.apply(filter_stop_words_on_a_span_list)\n",
    "\n",
    "generate_wordcloud(\" \".join( [\" \".join(doc) for doc in noun_phrase_corpus]) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Train LDA + LSI models\n",
    "\n",
    "- create a dictionary and a corpus with each corpora\n",
    "- train LDA models\n",
    "- train LSI models\n",
    "- visualize the results (LDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "word_dictionary = gensim.corpora.Dictionary(word_corpus)\n",
    "noun_dictionary = gensim.corpora.Dictionary(noun_corpus)\n",
    "verb_dictionary = gensim.corpora.Dictionary(verb_corpus)\n",
    "noun_phrases_dictionary = gensim.corpora.Dictionary(noun_phrase_corpus)\n",
    "\n",
    "word_gensim_corpus = [word_dictionary.doc2bow(docs) for docs in word_corpus]\n",
    "noun_gensim_corpus = [noun_dictionary.doc2bow(docs) for docs in noun_corpus]\n",
    "verb_gensim_corpus = [verb_dictionary.doc2bow(docs) for docs in verb_corpus]\n",
    "noun_phrases_gensim_corpus = [noun_phrases_dictionary.doc2bow(docs) for docs in noun_phrase_corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "word_lda_model = LdaModel(corpus=word_gensim_corpus, num_topics=5, id2word=word_dictionary, chunksize=30, random_state=40)\n",
    "noun_lda_model = LdaModel(corpus=noun_gensim_corpus, num_topics=4, id2word=noun_dictionary, chunksize=30, random_state=40)\n",
    "verb_lda_model = LdaModel(corpus=verb_gensim_corpus, num_topics=4, id2word=verb_dictionary, chunksize=20, random_state=40)\n",
    "noun_phrases_lda_model = LdaModel(corpus=noun_phrases_gensim_corpus, num_topics=5, id2word=noun_phrases_dictionary, chunksize=30, random_state=40)\n",
    "\n",
    "word_lsa_model = LsiModel(corpus=word_gensim_corpus, num_topics=6, id2word=word_dictionary, chunksize=300)\n",
    "noun_lsa_model = LsiModel(corpus=noun_gensim_corpus, num_topics=6, id2word=noun_dictionary, chunksize=300)\n",
    "verb_lsa_model = LsiModel(corpus=verb_gensim_corpus, num_topics=6, id2word=verb_dictionary, chunksize=300)\n",
    "noun_phrases_lsa_model = LsiModel(corpus=noun_phrases_gensim_corpus, num_topics=6, id2word=noun_phrases_dictionary, chunksize=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "pyLDAvis.enable_notebook()\n",
    "word_visualization = pyLDAvis.gensim_models.prepare(word_lda_model, word_gensim_corpus, word_dictionary)\n",
    "word_visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "noun_visualization = pyLDAvis.gensim_models.prepare(noun_lda_model, noun_gensim_corpus, noun_dictionary)\n",
    "noun_visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "t-SNE for noun_lda_model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Get the topics weights (nr. of docs. x nr. of topics)\n",
    "weights = np.zeros((len(eurlex), 4))\n",
    "\n",
    "for doc_nr, topics_info in enumerate(noun_lda_model[noun_gensim_corpus]):\n",
    "    for topic_info in topics_info:\n",
    "        topic_idx = topic_info[0]\n",
    "        topic_weight = topic_info[1]\n",
    "        weights[doc_nr][topic_idx] = topic_weight\n",
    "\n",
    "# Dominant topic number in each doc\n",
    "dominant_topics = np.argmax(weights, axis=1)\n",
    "\n",
    "# t-SNE Dimension Reduction\n",
    "t_sne_model = TSNE(n_components=2, verbose=1, random_state=42)\n",
    "t_sne_lda = t_sne_model.fit_transform(weights)\n",
    "\n",
    "# Plot the Topic Clusters using Bokeh\n",
    "output_notebook()\n",
    "n_topics = 4\n",
    "colors = np.array([color for name, color in mcolors.TABLEAU_COLORS.items()])\n",
    "\n",
    "source = ColumnDataSource(dict(\n",
    "    x=t_sne_lda[:,0],\n",
    "    y=t_sne_lda[:,1],\n",
    "    color=colors[dominant_topics],\n",
    "    label=pd.Series(dominant_topics).apply(lambda x: \"Topic \" + str(x + 1))\n",
    "))\n",
    "\n",
    "plot = figure(title=\"t-SNE Clustering of {} LDA Topics\".format(n_topics),\n",
    "              plot_width=900, plot_height=700)\n",
    "\n",
    "plot.scatter(x=\"x\", y=\"y\", color=\"color\", legend_group=\"label\", source=source)\n",
    "\n",
    "# Display legend in the top left corner\n",
    "plot.legend.location = \"top_left\"\n",
    "\n",
    "# Add a title to your legend\n",
    "plot.legend.title = \"Topics\"\n",
    "\n",
    "show(plot)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "verb_visualization = pyLDAvis.gensim_models.prepare(verb_lda_model, verb_gensim_corpus, verb_dictionary)\n",
    "verb_visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "noun_phrases_visualization = pyLDAvis.gensim_models.prepare(noun_phrases_lda_model, noun_phrases_gensim_corpus, noun_phrases_dictionary)\n",
    "noun_phrases_visualization\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}