{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-24 14:44:53.948766: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2021-08-24 14:44:53.948791: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"/home/jovyan/work/sem-covid/\")\n",
    "sys.path = list(set(sys.path))\n",
    "import os\n",
    "\n",
    "os.getcwd()\n",
    "os.chdir('/home/jovyan/work/sem-covid/')\n",
    "\n",
    "from sem_covid import config\n",
    "from sem_covid.services.store_registry import store_registry, StoreRegistryABC\n",
    "import hashlib\n",
    "from sem_covid.services.model_registry import EmbeddingModelRegistry, EmbeddingModelRegistryABC\n",
    "import spacy\n",
    "from more_itertools import windowed\n",
    "from typing import List\n",
    "import pandas as pd\n",
    "import concurrent"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "TEXTUAL_COLUMNS = ['title', 'content']\n",
    "FIN_REG_SPLITTED_ES_INDEX = 'ds_finreg_splitted'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "TEXTUAL_DATA = 'text_data'\n",
    "TEXT_PIECE = 'text_piece'\n",
    "DOCUMENT_ID_SOURCE = 'document_id_source'\n",
    "TEXT_PIECE_EMBEDDING = 'text_piece_embedding'\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [],
   "source": [
    "class WindowedSplitDocumentsPipeline:\n",
    "\n",
    "    def __init__(self, dataset_es_index_name: str,\n",
    "                 result_es_index_name: str,\n",
    "                 textual_columns: List[str],\n",
    "                 split_window_size: int,\n",
    "                 split_window_step: int,\n",
    "                 store_registry: StoreRegistryABC,\n",
    "                 embedding_model_registry: EmbeddingModelRegistryABC):\n",
    "        self.dataset_es_index_name = dataset_es_index_name\n",
    "        self.result_es_index_name = result_es_index_name\n",
    "        self.store_registry = store_registry\n",
    "        self.embedding_model_registry = embedding_model_registry\n",
    "        self.textual_columns = textual_columns\n",
    "        self.split_window_size = split_window_size\n",
    "        self.split_window_step = split_window_step\n",
    "        self.dataset = None\n",
    "        self.result_dataset = None\n",
    "\n",
    "    def load_dataset(self):\n",
    "        es_store = self.store_registry.es_index_store()\n",
    "        self.dataset = es_store.get_dataframe(self.dataset_es_index_name)\n",
    "        self.dataset = self.dataset[self.textual_columns]\n",
    "        self.dataset.dropna(inplace=True)\n",
    "\n",
    "    def prepare_textual_data(self):\n",
    "        for textual_column in self.textual_columns:\n",
    "            self.dataset = self.dataset[\n",
    "                self.dataset[textual_column].apply(lambda x: len(x) > 1)]\n",
    "        self.dataset[TEXTUAL_DATA] = self.dataset[self.textual_columns].agg(lambda texts:\n",
    "                                                                            \". \".join(texts),\n",
    "                                                                            axis=1)\n",
    "\n",
    "    def split_documents(self):\n",
    "        def split_documents_worker(index,value,window_size,window_step):\n",
    "            sentences = [sent.text for sent in nlp(value).sents]\n",
    "            windowed_texts = list(\n",
    "                windowed(sentences,\n",
    "                         n=window_size,\n",
    "                         fillvalue='',\n",
    "                         step=window_step)\n",
    "            )\n",
    "            return [(index, ' '.join(windowed_text))\n",
    "                    for windowed_text in windowed_texts]\n",
    "        with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "            futures = [executor.submit(split_documents_worker,\n",
    "                                       index,\n",
    "                                       value[:1000000],\n",
    "                                       self.split_window_size,\n",
    "                                       self.split_window_step\n",
    "                                       )\n",
    "                       for index, value in self.dataset[TEXTUAL_DATA][:1].items()\n",
    "                       #[WARNING]!!Delete limit of dataset in production!\n",
    "                       ]\n",
    "            self.result_dataset = pd.DataFrame([result\n",
    "                                                for future in futures for result in future.result()],\n",
    "                                               columns=[DOCUMENT_ID_SOURCE,TEXT_PIECE])\n",
    "\n",
    "    def compute_embeddings(self):\n",
    "        emb_model = self.embedding_model_registry.sent2vec_universal_sent_encoding()\n",
    "        self.result_dataset[TEXT_PIECE_EMBEDDING] = emb_model.encode(self.result_dataset[TEXT_PIECE].values)\n",
    "\n",
    "    def store_splitted_documents(self):\n",
    "        self.result_dataset.reset_index(drop=True, inplace=True)\n",
    "        es_store = self.store_registry.es_index_store()\n",
    "        es_store.put_dataframe(index_name=self.result_es_index_name,\n",
    "                               content=self.result_dataset)\n",
    "\n",
    "    def execute(self):\n",
    "        self.load_dataset()\n",
    "        self.prepare_textual_data()\n",
    "        self.split_documents()\n",
    "        self.compute_embeddings()\n",
    "        self.store_splitted_documents()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [],
   "source": [
    "windowed_split_documents_pipeline = WindowedSplitDocumentsPipeline(\n",
    "    dataset_es_index_name=config.EU_FINREG_CELLAR_ELASTIC_SEARCH_INDEX_NAME,\n",
    "    result_es_index_name=FIN_REG_SPLITTED_ES_INDEX,\n",
    "    textual_columns=TEXTUAL_COLUMNS,\n",
    "    split_window_size=10,\n",
    "    split_window_step=5,\n",
    "    store_registry=store_registry,\n",
    "    embedding_model_registry=EmbeddingModelRegistry())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (5757 of 5757) |####################| Elapsed Time: 0:00:01 Time:  0:00:01\n",
      "N/A% (0 of 28) |                         | Elapsed Time: 0:00:00 ETA:  --:--:--"
     ]
    }
   ],
   "source": [
    "windowed_split_documents_pipeline.execute()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "outputs": [],
   "source": [
    "import faiss\n",
    "import numpy as np"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "\n",
    "class FaissIndexingPipeline:\n",
    "\n",
    "    def __init__(self, es_index_name: str,\n",
    "                 embedding_column_name: str,\n",
    "                 result_bucket_name: str,\n",
    "                 result_faiss_index_name: str,\n",
    "                 store_registry: StoreRegistryABC):\n",
    "        self.es_index_name = es_index_name\n",
    "        self.store_registry = store_registry\n",
    "        self.embedding_column_name = embedding_column_name\n",
    "        self.result_bucket_name = result_bucket_name\n",
    "        self.result_faiss_index_name = result_faiss_index_name\n",
    "        self.dataset = None\n",
    "        self.embeddings = None\n",
    "        self.faiss_index = None\n",
    "\n",
    "    def load_dataset(self):\n",
    "        es_store = self.store_registry.es_index_store()\n",
    "        self.dataset = es_store.get_dataframe(index_name=self.es_index_name)\n",
    "\n",
    "    def prepare_embeddings(self):\n",
    "        self.embeddings = self.dataset[self.embedding_column_name].values\n",
    "        self.embeddings = np.array([np.array(embedding).astype('float32')\n",
    "                                    for embedding in self.embeddings]).astype(\"float32\")\n",
    "\n",
    "    def embeddings_indexing(self):\n",
    "        self.faiss_index = faiss.IndexFlatL2(self.embeddings.shape[1])\n",
    "        self.faiss_index = faiss.IndexIDMap(self.faiss_index)\n",
    "        self.faiss_index.add_with_ids(self.embeddings, self.dataset.index.values)\n",
    "\n",
    "    def store_faiss_index(self):\n",
    "        minio_store = store_registry.minio_object_store(self.result_bucket_name)\n",
    "        minio_store.put_object(object_name=self.result_faiss_index_name,\n",
    "                               content=pickle.dumps(faiss.serialize_index(self.faiss_index))\n",
    "                               )\n",
    "\n",
    "    def execute(self):\n",
    "        self.load_dataset()\n",
    "        self.prepare_embeddings()\n",
    "        self.embeddings_indexing()\n",
    "        self.store_faiss_index()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "faiss_indexing_pipeline = FaissIndexingPipeline(es_index_name=FIN_REG_SPLITTED_ES_INDEX,\n",
    "                                                embedding_column_name=TEXT_PIECE_EMBEDDING,\n",
    "                                                result_bucket_name=,\n",
    "                                                result_faiss_index_name=,\n",
    "                                                store_registry=)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "outputs": [],
   "source": [
    "embeddings = new_df.text_piece_embedding.values"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "outputs": [],
   "source": [
    "embeddings = np.array([np.array(embedding).astype('float32')\n",
    "                       for embedding in embeddings]).astype(\"float32\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of vectors in the Faiss index: 1402\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Instantiate the index\n",
    "index = faiss.IndexFlatL2(embeddings.shape[1])\n",
    "\n",
    "# Step 3: Pass the index to IndexIDMap\n",
    "index = faiss.IndexIDMap(index)\n",
    "\n",
    "# Step 4: Add vectors and their IDs\n",
    "index.add_with_ids(embeddings, np.array(range(0, embeddings.shape[0])))\n",
    "\n",
    "print(f\"Number of vectors in the Faiss index: {index.ntotal}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L2 distance: [0.0, 0.22245340049266815, 0.5410061478614807, 0.5424696207046509, 0.5697960257530212, 0.620814323425293, 0.6340034604072571, 0.6435337662696838, 0.6524192690849304, 0.6616794466972351, 0.7028501033782959, 0.7037103176116943, 0.7069353461265564, 0.7169807553291321, 0.7531577944755554, 0.8260558843612671, 0.8626027703285217, 0.86916583776474, 0.8854991793632507, 0.9011704325675964, 0.9037261605262756, 0.9388514161109924, 0.9419631958007812, 0.9499005675315857, 0.9517160058021545, 0.9522029161453247, 0.9544087648391724, 0.9546146392822266, 0.9648861289024353, 0.9708071947097778, 0.9726360440254211, 0.974346935749054, 0.978111982345581, 0.9861728549003601, 0.9889810681343079, 0.9891105890274048, 0.9891105890274048, 0.9996849298477173, 1.0014151334762573, 1.0050978660583496, 1.0118540525436401, 1.021659255027771, 1.0343246459960938, 1.035066843032837, 1.0373544692993164, 1.0446761846542358, 1.0454301834106445, 1.0566376447677612, 1.0566376447677612, 1.0648467540740967]\n",
      "\n",
      "MAG paper IDs: [0, 1, 6, 3, 15, 9, 7, 10, 4, 2, 8, 16, 11, 14, 17, 13, 18, 12, 5, 20, 1049, 1082, 1195, 1187, 1136, 1099, 1096, 1184, 1188, 1185, 1171, 1182, 1098, 1095, 1170, 1048, 1145, 1083, 1135, 1093, 1097, 1151, 1092, 1186, 1181, 21, 1058, 1055, 1148, 1054]\n"
     ]
    }
   ],
   "source": [
    "# Retrieve the 10 nearest neighbours\n",
    "D, I = index.search(np.array([embeddings[0]]), k=50)\n",
    "print(f'L2 distance: {D.flatten().tolist()}\\n\\nMAG paper IDs: {I.flatten().tolist()}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "outputs": [
    {
     "data": {
      "text/plain": "array(['483380ec660eea125bd574565bef076acd782f2297f5b0a51f513a30e04a8f5a',\n       '483380ec660eea125bd574565bef076acd782f2297f5b0a51f513a30e04a8f5a',\n       '483380ec660eea125bd574565bef076acd782f2297f5b0a51f513a30e04a8f5a',\n       '483380ec660eea125bd574565bef076acd782f2297f5b0a51f513a30e04a8f5a',\n       '483380ec660eea125bd574565bef076acd782f2297f5b0a51f513a30e04a8f5a',\n       '483380ec660eea125bd574565bef076acd782f2297f5b0a51f513a30e04a8f5a',\n       '483380ec660eea125bd574565bef076acd782f2297f5b0a51f513a30e04a8f5a',\n       '483380ec660eea125bd574565bef076acd782f2297f5b0a51f513a30e04a8f5a',\n       '483380ec660eea125bd574565bef076acd782f2297f5b0a51f513a30e04a8f5a',\n       '483380ec660eea125bd574565bef076acd782f2297f5b0a51f513a30e04a8f5a',\n       '483380ec660eea125bd574565bef076acd782f2297f5b0a51f513a30e04a8f5a',\n       '483380ec660eea125bd574565bef076acd782f2297f5b0a51f513a30e04a8f5a',\n       '483380ec660eea125bd574565bef076acd782f2297f5b0a51f513a30e04a8f5a',\n       '483380ec660eea125bd574565bef076acd782f2297f5b0a51f513a30e04a8f5a',\n       '483380ec660eea125bd574565bef076acd782f2297f5b0a51f513a30e04a8f5a',\n       '483380ec660eea125bd574565bef076acd782f2297f5b0a51f513a30e04a8f5a',\n       '483380ec660eea125bd574565bef076acd782f2297f5b0a51f513a30e04a8f5a',\n       '483380ec660eea125bd574565bef076acd782f2297f5b0a51f513a30e04a8f5a',\n       '483380ec660eea125bd574565bef076acd782f2297f5b0a51f513a30e04a8f5a',\n       '483380ec660eea125bd574565bef076acd782f2297f5b0a51f513a30e04a8f5a',\n       '4ae662bd92c092d7fd24f3d8b7b76186ae3ac7c16613b5b2816aff49cca6d72a',\n       '4ae662bd92c092d7fd24f3d8b7b76186ae3ac7c16613b5b2816aff49cca6d72a',\n       '4ae662bd92c092d7fd24f3d8b7b76186ae3ac7c16613b5b2816aff49cca6d72a',\n       '4ae662bd92c092d7fd24f3d8b7b76186ae3ac7c16613b5b2816aff49cca6d72a',\n       '4ae662bd92c092d7fd24f3d8b7b76186ae3ac7c16613b5b2816aff49cca6d72a',\n       '4ae662bd92c092d7fd24f3d8b7b76186ae3ac7c16613b5b2816aff49cca6d72a',\n       '4ae662bd92c092d7fd24f3d8b7b76186ae3ac7c16613b5b2816aff49cca6d72a',\n       '4ae662bd92c092d7fd24f3d8b7b76186ae3ac7c16613b5b2816aff49cca6d72a',\n       '4ae662bd92c092d7fd24f3d8b7b76186ae3ac7c16613b5b2816aff49cca6d72a',\n       '4ae662bd92c092d7fd24f3d8b7b76186ae3ac7c16613b5b2816aff49cca6d72a',\n       '4ae662bd92c092d7fd24f3d8b7b76186ae3ac7c16613b5b2816aff49cca6d72a',\n       '4ae662bd92c092d7fd24f3d8b7b76186ae3ac7c16613b5b2816aff49cca6d72a',\n       '4ae662bd92c092d7fd24f3d8b7b76186ae3ac7c16613b5b2816aff49cca6d72a',\n       '4ae662bd92c092d7fd24f3d8b7b76186ae3ac7c16613b5b2816aff49cca6d72a',\n       '4ae662bd92c092d7fd24f3d8b7b76186ae3ac7c16613b5b2816aff49cca6d72a',\n       '4ae662bd92c092d7fd24f3d8b7b76186ae3ac7c16613b5b2816aff49cca6d72a',\n       '4ae662bd92c092d7fd24f3d8b7b76186ae3ac7c16613b5b2816aff49cca6d72a',\n       '4ae662bd92c092d7fd24f3d8b7b76186ae3ac7c16613b5b2816aff49cca6d72a',\n       '4ae662bd92c092d7fd24f3d8b7b76186ae3ac7c16613b5b2816aff49cca6d72a',\n       '4ae662bd92c092d7fd24f3d8b7b76186ae3ac7c16613b5b2816aff49cca6d72a',\n       '4ae662bd92c092d7fd24f3d8b7b76186ae3ac7c16613b5b2816aff49cca6d72a',\n       '4ae662bd92c092d7fd24f3d8b7b76186ae3ac7c16613b5b2816aff49cca6d72a',\n       '4ae662bd92c092d7fd24f3d8b7b76186ae3ac7c16613b5b2816aff49cca6d72a',\n       '4ae662bd92c092d7fd24f3d8b7b76186ae3ac7c16613b5b2816aff49cca6d72a',\n       '4ae662bd92c092d7fd24f3d8b7b76186ae3ac7c16613b5b2816aff49cca6d72a',\n       '483380ec660eea125bd574565bef076acd782f2297f5b0a51f513a30e04a8f5a',\n       '4ae662bd92c092d7fd24f3d8b7b76186ae3ac7c16613b5b2816aff49cca6d72a',\n       '4ae662bd92c092d7fd24f3d8b7b76186ae3ac7c16613b5b2816aff49cca6d72a',\n       '4ae662bd92c092d7fd24f3d8b7b76186ae3ac7c16613b5b2816aff49cca6d72a',\n       '4ae662bd92c092d7fd24f3d8b7b76186ae3ac7c16613b5b2816aff49cca6d72a'],\n      dtype=object)"
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df.iloc[I.flatten().tolist()].document_source.values"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "outputs": [
    {
     "data": {
      "text/plain": "[0.0,\n 0.22245340049266815,\n 0.5410061478614807,\n 0.5424696207046509,\n 0.5697960257530212,\n 0.620814323425293,\n 0.6340034604072571,\n 0.6435337662696838,\n 0.6524192690849304,\n 0.6616794466972351,\n 0.7028501033782959,\n 0.7037103176116943,\n 0.7069353461265564,\n 0.7169807553291321,\n 0.7531577944755554,\n 0.8260558843612671,\n 0.8626027703285217,\n 0.86916583776474,\n 0.8854991793632507,\n 0.9011704325675964,\n 0.9037261605262756,\n 0.9388514161109924,\n 0.9419631958007812,\n 0.9499005675315857,\n 0.9517160058021545,\n 0.9522029161453247,\n 0.9544087648391724,\n 0.9546146392822266,\n 0.9648861289024353,\n 0.9708071947097778,\n 0.9726360440254211,\n 0.974346935749054,\n 0.978111982345581,\n 0.9861728549003601,\n 0.9889810681343079,\n 0.9891105890274048,\n 0.9891105890274048,\n 0.9996849298477173,\n 1.0014151334762573,\n 1.0050978660583496,\n 1.0118540525436401,\n 1.021659255027771,\n 1.0343246459960938,\n 1.035066843032837,\n 1.0373544692993164,\n 1.0446761846542358,\n 1.0454301834106445,\n 1.0566376447677612,\n 1.0566376447677612,\n 1.0648467540740967]"
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "D.flatten().tolist()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}