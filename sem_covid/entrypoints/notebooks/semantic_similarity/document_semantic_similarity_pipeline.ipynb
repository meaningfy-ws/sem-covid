{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"/home/jovyan/work/sem-covid/\")\n",
    "sys.path = list(set(sys.path))\n",
    "import os\n",
    "\n",
    "os.getcwd()\n",
    "os.chdir('/home/jovyan/work/sem-covid/')\n",
    "from sem_covid import config\n",
    "from sem_covid.services.model_registry import embedding_registry\n",
    "from pathlib import Path\n",
    "from sem_covid.services.store_registry import store_registry\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.spatial.distance import euclidean\n",
    "from sem_covid.services.semantic_similarity_pipelines.document_embedding_pipeline import DocumentEmbeddingPipeline"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "def cosine(u, v):\n",
    "    return np.dot(u, v) / (np.linalg.norm(u) * np.linalg.norm(v))\n",
    "\n",
    "\n",
    "def similarity_func(u, v):\n",
    "    return 1 / (1 + euclidean(u, v))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "TEXTUAL_COLUMNS = ['title', 'background_info_description', 'content_of_measure_description',\n",
    "                   'use_of_measure_description', 'involvement_of_social_partners_description']\n",
    "\n",
    "DOCUMENT_EMBEDDINGS_FEATURE_STORE_NAME = 'fs_doc_emb_tfidf'\n",
    "\n",
    "DOCUMENTS_CONFIGS = {config.IRELAND_TIMELINE_ELASTIC_SEARCH_INDEX_NAME: ['title', 'content'],\n",
    "                     config.EU_TIMELINE_ELASTIC_SEARCH_INDEX_NAME: ['title', 'abstract', 'detail_content'],\n",
    "                     config.EU_CELLAR_ELASTIC_SEARCH_INDEX_NAME: ['title', 'content'],\n",
    "                     config.PWDB_ELASTIC_SEARCH_INDEX_NAME: TEXTUAL_COLUMNS\n",
    "                     }"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (410 of 410) |######################| Elapsed Time: 0:00:00 Time:  0:00:00\n",
      "100% (171 of 171) |######################| Elapsed Time: 0:00:00 Time:  0:00:00\n",
      "100% (2818 of 2818) |####################| Elapsed Time: 0:00:00 Time:  0:00:00\n",
      "100% (1288 of 1288) |####################| Elapsed Time: 0:00:00 Time:  0:00:00\n",
      " 74% (962 of 1288) |###############      | Elapsed Time: 0:00:00 ETA:  00:00:00"
     ]
    }
   ],
   "source": [
    "for config_key in DOCUMENTS_CONFIGS.keys():\n",
    "    DocumentEmbeddingPipeline(es_index_name=config_key,\n",
    "                              textual_columns=DOCUMENTS_CONFIGS[config_key],\n",
    "                              embedding_model=embedding_registry.sent2vec_tfidf_avg(),\n",
    "                              embedding_model_name='TfIdfEmbeddingModel',\n",
    "                              store_registry=store_registry,\n",
    "                              doc_emb_feature_store_name=DOCUMENT_EMBEDDINGS_FEATURE_STORE_NAME\n",
    "                              ).execute()\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "import concurrent.futures\n",
    "import hashlib\n",
    "\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics import pairwise_distances\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "from sem_covid.services.semantic_similarity_pipelines.document_embedding_pipeline import DOCUMENT_EMBEDDING,\n",
    "\n",
    "DOCUMENT_EMBEDDING_METHOD\n",
    "from sem_covid.services.store_registry import StoreRegistryABC\n",
    "\n",
    "DOCUMENT_NAME_X = 'name_x'\n",
    "DOCUMENT_NAME_Y = 'name_y'\n",
    "SIMILARITY_MATRIX = 'similarity_matrix'\n",
    "SIMILARITY_LIST = 'similarity_list'\n",
    "DOCUMENT_ID = 'document_id'\n",
    "SIMILARITY_METRIC = 'similarity_metric'\n",
    "SIMILARITY_METRIC_VALUE = 'similarity_metric_value'\n",
    "DOCUMENT_EMBEDDING_METHOD_NOT_FOUND = 'not_found_embedding_method'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "class DocumentSimilarityPipeline:\n",
    "\n",
    "    def __init__(self, document_embeddings_index: str, similarity_metric,\n",
    "                 similarity_metric_name: str,\n",
    "                 store_registry: StoreRegistryABC,\n",
    "                 figures_path: Path = None\n",
    "                 ):\n",
    "        self.document_embeddings_index = document_embeddings_index\n",
    "        self.similarity_metric = similarity_metric\n",
    "        self.prepared_data = None\n",
    "        self.document_embeddings = {}\n",
    "        self.dataset_names = []\n",
    "        self.figures_path = figures_path\n",
    "        self.store_registry = store_registry\n",
    "        self.similarity_metric_name = similarity_metric_name\n",
    "        self.document_embeddings_method = DOCUMENT_EMBEDDING_METHOD_NOT_FOUND\n",
    "        self.dataset = pd.DataFrame()\n",
    "\n",
    "    def load_document_embeddings(self):\n",
    "        es_index_store = self.store_registry.es_index_store()\n",
    "        self.dataset = es_index_store.get_dataframe(index_name=self.document_embeddings_index)\n",
    "        self.dataset_names = list(set(self.dataset.source.values))\n",
    "        self.document_embeddings = {dataset_name: self.dataset[self.dataset.source == dataset_name]\n",
    "                                    for dataset_name in self.dataset_names}\n",
    "\n",
    "    def prepare_similarity_data(self):\n",
    "        def prepare_worker(name_x: str, name_y: str):\n",
    "            similarity_matrix = pd.DataFrame(\n",
    "                pairwise_distances(X=self.document_embeddings[name_x][DOCUMENT_EMBEDDING].to_list(),\n",
    "                                   Y=self.document_embeddings[name_y][DOCUMENT_EMBEDDING].to_list(),\n",
    "                                   metric=self.similarity_metric),\n",
    "                columns=self.document_embeddings[name_y].index.to_list(),\n",
    "                index=self.document_embeddings[name_x].index.to_list()\n",
    "            )\n",
    "            similarity_matrix_values = similarity_matrix.values\n",
    "            similarity_list = [similarity_matrix_values[row][col]\n",
    "                               for row in range(0, similarity_matrix_values.shape[0])\n",
    "                               for col in range(row + 1, similarity_matrix_values.shape[1])]\n",
    "\n",
    "            return {DOCUMENT_NAME_X: name_x, DOCUMENT_NAME_Y: name_y,\n",
    "                    SIMILARITY_MATRIX: similarity_matrix,\n",
    "                    SIMILARITY_LIST: similarity_list}\n",
    "\n",
    "        with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "            futures = [executor.submit(prepare_worker, name_x, name_y)\n",
    "                       for name_x in self.dataset_names\n",
    "                       for name_y in self.dataset_names[self.dataset_names.index(name_x):]]\n",
    "            self.prepared_data = [future.result() for future in futures]\n",
    "\n",
    "    def save_similarity_matrix(self):\n",
    "        minio_feature_store = self.store_registry.minio_feature_store()\n",
    "        self.document_embeddings_method = list(self.document_embeddings.values())[0][DOCUMENT_EMBEDDING_METHOD][0]\n",
    "        for data in self.prepared_data:\n",
    "            similarity_documents_name = f\"{data[DOCUMENT_NAME_X]}_X_{data[DOCUMENT_NAME_Y]}\"\n",
    "            similarity_feature_name = \"_\".join([\"sm\",\n",
    "                                                similarity_documents_name,\n",
    "                                                self.document_embeddings_method,\n",
    "                                                self.similarity_metric_name]\n",
    "                                               )\n",
    "            minio_feature_store.put_features(features_name=similarity_feature_name,\n",
    "                                             content=data[SIMILARITY_MATRIX]\n",
    "                                             )\n",
    "\n",
    "    def save_similarity_pairs(self):\n",
    "\n",
    "        def generate_new_row(row_index, dataframe, column_suffix):\n",
    "            new_row = pd.Series(dataframe.loc[row_index])\n",
    "            new_row[DOCUMENT_ID] = new_row.name\n",
    "            new_row.index = list(map(lambda x: x + column_suffix, new_row.index))\n",
    "            return new_row\n",
    "\n",
    "        def combine_two_rows(left_row: pd.Series, right_row: pd.Series, similarity_metric: str,\n",
    "                             similarity_metric_value: float) -> pd.Series:\n",
    "            new_combined_row = left_row.append(right_row)\n",
    "            new_combined_row[SIMILARITY_METRIC] = similarity_metric\n",
    "            new_combined_row[SIMILARITY_METRIC_VALUE] = similarity_metric_value\n",
    "            new_combined_row.name = hashlib.sha256(\n",
    "                (str(left_row.name) + str(right_row.name)).encode('utf-8')).hexdigest()\n",
    "            return new_combined_row\n",
    "\n",
    "        es_index_store = self.store_registry.es_index_store()\n",
    "\n",
    "        for data in self.prepared_data:\n",
    "            sim_matrix = data[SIMILARITY_MATRIX]\n",
    "            sim_pairs_list = [combine_two_rows(generate_new_row(row_index_left, self.dataset, '_left'),\n",
    "                                               generate_new_row(row_index_right, self.dataset, '_right'),\n",
    "                                               self.similarity_metric_name,\n",
    "                                               sim_matrix.loc[row_index_left][row_index_right])\n",
    "                              for row_index_left in sim_matrix.index\n",
    "                              for row_index_right in sim_matrix.columns]\n",
    "            similarity_pairs_df = pd.DataFrame(sim_pairs_list)\n",
    "            es_index_store.put_dataframe(index_name=f\"sm_{data[DOCUMENT_NAME_X]}_X_{data[DOCUMENT_NAME_Y]}\",\n",
    "                                         content=similarity_pairs_df)\n",
    "\n",
    "    def plot_histograms(self):\n",
    "        if self.figures_path:\n",
    "            plt.subplots(figsize=(10, 5))\n",
    "            for data in self.prepared_data:\n",
    "                plot_title = f\"sm_{data[DOCUMENT_NAME_X]}_X_{data[DOCUMENT_NAME_Y]}_{self.document_embeddings_method}\"\n",
    "                plot = sns.histplot(data=data[SIMILARITY_LIST]).set_title(plot_title)\n",
    "                plot.figure.savefig(self.figures_path / (plot_title + '.png'))\n",
    "                plot.figure.clf()\n",
    "\n",
    "    def execute(self):\n",
    "        self.load_document_embeddings()\n",
    "        self.prepare_similarity_data()\n",
    "        self.save_similarity_matrix()\n",
    "        self.save_similarity_pairs()\n",
    "        self.plot_histograms()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "doc_sim = DocumentSimilarityPipeline(document_embeddings_index=DOCUMENT_EMBEDDINGS_FEATURE_STORE_NAME,\n",
    "                                     similarity_metric=cosine,\n",
    "                                     similarity_metric_name='cosine_similarity',\n",
    "                                     store_registry=store_registry\n",
    "                                     )"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (2490 of 2490) |####################| Elapsed Time: 0:00:00 Time:  0:00:00\n"
     ]
    }
   ],
   "source": [
    "doc_sim.load_document_embeddings()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "doc_sim.prepare_similarity_data()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-22-f48dde70a652>:3: DeprecationWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  new_row = pd.Series()\n"
     ]
    }
   ],
   "source": [
    "def save_similarity_pairs(self):\n",
    "    def generate_new_row(row_index, dataframe, column_suffix):\n",
    "        new_row = pd.Series()\n",
    "        new_row.name = dataframe.loc[row_index].name\n",
    "        new_row[DOCUMENT_ID] = new_row.name\n",
    "        new_row.index = list(map(lambda x: x + column_suffix, new_row.index))\n",
    "        return new_row\n",
    "\n",
    "    def combine_two_rows(left_row: pd.Series, right_row: pd.Series, similarity_metric: str,\n",
    "                         similarity_metric_value: float) -> pd.Series:\n",
    "        new_combined_row = left_row.append(right_row)\n",
    "        new_combined_row[SIMILARITY_METRIC] = similarity_metric\n",
    "        new_combined_row[SIMILARITY_METRIC_VALUE] = similarity_metric_value\n",
    "        new_combined_row.name = hashlib.sha256(\n",
    "            (str(left_row.name) + str(right_row.name)).encode('utf-8')).hexdigest()\n",
    "        return new_combined_row\n",
    "\n",
    "    #es_index_store = self.store_registry.es_index_store()\n",
    "\n",
    "    def similarity_pairs_worker(sim_matrix: pd.DataFrame,doc_name_1,doc_name_2) -> pd.DataFrame:\n",
    "        print(f'similarity start {doc_name_1}X{doc_name_2}')\n",
    "        sim_pairs_list = [combine_two_rows(generate_new_row(row_index_left, self.dataset, '_left'),\n",
    "                                           generate_new_row(row_index_right, self.dataset, '_right'),\n",
    "                                           self.similarity_metric_name,\n",
    "                                           sim_matrix.loc[row_index_left][row_index_right])\n",
    "                          for row_index_left in sim_matrix.index\n",
    "                          for row_index_right in sim_matrix.columns]\n",
    "        print(f'similarity finish {doc_name_1}X{doc_name_2}')\n",
    "        return pd.DataFrame(sim_pairs_list)\n",
    "\n",
    "    with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "        futures = [executor.submit(similarity_pairs_worker, data[SIMILARITY_MATRIX],\n",
    "                                   data[DOCUMENT_NAME_X],\n",
    "                                   data[DOCUMENT_NAME_Y])\n",
    "                   for data in self.prepared_data]\n",
    "        return [future.result() for future in futures]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "similarity start ds_pwdbXds_pwdb\n",
      "similarity start ds_pwdbXds_eu_cellar\n",
      "similarity start ds_pwdbXds_ireland_timeline\n",
      "similarity start ds_pwdbXds_eu_timeline\n",
      "similarity start ds_eu_cellarXds_eu_cellar\n",
      "similarity start ds_eu_cellarXds_ireland_timeline\n",
      "similarity start ds_eu_cellarXds_eu_timeline\n",
      "similarity start ds_ireland_timelineXds_ireland_timeline\n",
      "similarity start ds_ireland_timelineXds_eu_timeline\n",
      "similarity start ds_eu_timelineXds_eu_timeline\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-24-5fb3e6bfb4d9>:3: DeprecationWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  new_row = pd.Series()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "similarity pairs compute finish!\n",
      "similarity finish ds_eu_timelineXds_eu_timeline\n",
      "similarity pairs compute finish!\n",
      "similarity finish ds_ireland_timelineXds_eu_timeline\n",
      "similarity finish ds_eu_cellarXds_eu_timeline\n",
      "similarity pairs compute finish!\n",
      "similarity pairs compute finish!\n",
      "similarity finish ds_ireland_timelineXds_ireland_timeline\n",
      "similarity finish ds_pwdbXds_eu_timeline\n",
      "similarity pairs compute finish!\n"
     ]
    }
   ],
   "source": [
    "results = save_similarity_pairs(doc_sim)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "a bytes-like object is required, not 'DataFrame'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-32-cc682ab82aec>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0mdoc_sim\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msave_similarity_matrix\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;32m<ipython-input-28-de20addda86b>\u001B[0m in \u001B[0;36msave_similarity_matrix\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m     58\u001B[0m                                                 self.similarity_metric_name]\n\u001B[1;32m     59\u001B[0m                                                )\n\u001B[0;32m---> 60\u001B[0;31m             minio_feature_store.put_features(features_name=similarity_feature_name,\n\u001B[0m\u001B[1;32m     61\u001B[0m                                              \u001B[0mcontent\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mdata\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mSIMILARITY_MATRIX\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     62\u001B[0m                                              )\n",
      "\u001B[0;32m~/work/sem-covid/sem_covid/adapters/minio_feature_store.py\u001B[0m in \u001B[0;36mput_features\u001B[0;34m(self, features_name, content)\u001B[0m\n\u001B[1;32m     20\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     21\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mput_features\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mfeatures_name\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mstr\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mcontent\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mpd\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mDataFrame\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 22\u001B[0;31m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_object_store\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mput_object\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mobject_name\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mfeatures_name\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mcontent\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mcontent\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;32m~/work/sem-covid/sem_covid/adapters/minio_object_store.py\u001B[0m in \u001B[0;36mput_object\u001B[0;34m(self, object_name, content)\u001B[0m\n\u001B[1;32m     47\u001B[0m             \u001B[0mraw_content\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mio\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mBytesIO\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mbytes\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mcontent\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mencoding\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m'utf8'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     48\u001B[0m         \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 49\u001B[0;31m             \u001B[0mraw_content\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mio\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mBytesIO\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mcontent\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     50\u001B[0m         \u001B[0mraw_content_size\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mraw_content\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mgetbuffer\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mnbytes\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     51\u001B[0m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mminio_client\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mput_object\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mminio_bucket\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mobject_name\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mraw_content\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mraw_content_size\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mTypeError\u001B[0m: a bytes-like object is required, not 'DataFrame'"
     ]
    }
   ],
   "source": [
    "doc_sim.save_similarity_matrix()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "doc_sim.save_similarity_pairs()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "doc_sim.plot_histograms()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}