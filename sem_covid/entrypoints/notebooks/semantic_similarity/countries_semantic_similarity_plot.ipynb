{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"/home/jovyan/work/sem-covid/\")\n",
    "sys.path = list(set(sys.path))\n",
    "import os\n",
    "\n",
    "os.getcwd()\n",
    "os.chdir('/home/jovyan/work/sem-covid/')\n",
    "from sem_covid.services.store_registry import store_registry\n",
    "from sem_covid import config\n",
    "from sem_covid.services.model_registry import embedding_registry\n",
    "\n",
    "from typing import Any\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import plotly.express as px\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from numpy import mean\n",
    "from more_itertools import unique_everseen\n",
    "from typing import List"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Define constants"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "UNIFIED_DATASET = 'ds_unified_datasets'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "es_store = store_registry.es_index_store()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Load data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (1381 of 1381) |####################| Elapsed Time: 0:00:00 Time:  0:00:00\n",
      "100% (4126 of 4126) |####################| Elapsed Time: 0:00:00 Time:  0:00:00\n",
      "INFO:absl:Using /tmp/tfhub_modules to cache modules.\n"
     ]
    }
   ],
   "source": [
    "pwdb_df = es_store.get_dataframe(index_name=config.PWDB_ELASTIC_SEARCH_INDEX_NAME)\n",
    "unified_df = es_store.get_dataframe(index_name=UNIFIED_DATASET)\n",
    "emb_model = embedding_registry.sent2vec_universal_sent_encoding()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Compute embeddings based on textual fields"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "unified_df = pd.DataFrame(unified_df[unified_df.Document_source == 'pwdb'])\n",
    "unified_df['text'] = unified_df[['Title', 'Content']].agg(' '.join, axis=1)\n",
    "unified_df['emb'] = emb_model.encode(unified_df['text'].values)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [],
   "source": [
    "tmp = np.hstack(pwdb_df['subcategory'].str.split(',').apply(lambda x: list(map(str.strip, x))).values.tolist())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "outputs": [
    {
     "data": {
      "text/plain": "Index(['Date', 'Title', 'Content', 'Document_source', 'text', 'emb'], dtype='object')"
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unified_df.columns"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "outputs": [],
   "source": [
    "country_filter = pwdb_df[pwdb_df.country=='Spain'].index.tolist()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "outputs": [],
   "source": [
    "tmp_df = unified_df.loc[country_filter]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "outputs": [
    {
     "data": {
      "text/plain": "                                                          Date  \\\n_id                                                              \ntika/ff1e9f1110f125c9c37841268b37cc9ab2af55e3a0...  2020-03-31   \n\n                                                                                                Title  \\\n_id                                                                                                     \ntika/ff1e9f1110f125c9c37841268b37cc9ab2af55e3a0...  Extension of protection for unemployment benefits   \n\n                                                                                              Content  \\\n_id                                                                                                     \ntika/ff1e9f1110f125c9c37841268b37cc9ab2af55e3a0...  This extraordinary legislation supplements exi...   \n\n                                                   Document_source  \\\n_id                                                                  \ntika/ff1e9f1110f125c9c37841268b37cc9ab2af55e3a0...            pwdb   \n\n                                                                                                 text  \\\n_id                                                                                                     \ntika/ff1e9f1110f125c9c37841268b37cc9ab2af55e3a0...  Extension of protection for unemployment benef...   \n\n                                                                                                  emb  \n_id                                                                                                    \ntika/ff1e9f1110f125c9c37841268b37cc9ab2af55e3a0...  [0.04423779994249344, -0.06124040484428406, -0...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Date</th>\n      <th>Title</th>\n      <th>Content</th>\n      <th>Document_source</th>\n      <th>text</th>\n      <th>emb</th>\n    </tr>\n    <tr>\n      <th>_id</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>tika/ff1e9f1110f125c9c37841268b37cc9ab2af55e3a091bdf0996e6395ab093943</th>\n      <td>2020-03-31</td>\n      <td>Extension of protection for unemployment benefits</td>\n      <td>This extraordinary legislation supplements exi...</td>\n      <td>pwdb</td>\n      <td>Extension of protection for unemployment benef...</td>\n      <td>[0.04423779994249344, -0.06124040484428406, -0...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(tmp_df.groupby(['Date']))[1][0]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [],
   "source": [
    "t = pd.Series(tmp).value_counts(normalize=True).nlargest(5)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Define auxiliary functions:\n",
    "- prepare_df - function for data filtering\n",
    "- top_k_mean - function for computing the mean from greatest k terms"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "def prepare_df(unified_df: pd.DataFrame,\n",
    "               pwdb_df: pd.DataFrame,\n",
    "               column_filter_name: str,\n",
    "               column_filter_value: Any\n",
    "               ):\n",
    "    search_index = pwdb_df[pwdb_df[column_filter_name] == column_filter_value].index.values\n",
    "    result_df = pd.DataFrame(unified_df[unified_df.index.isin(search_index)])\n",
    "    return result_df\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "def top_k_mean(data: np.array, top_k: int):\n",
    "    tmp_data = data.copy().tolist()\n",
    "    tmp_data.sort(reverse=True)\n",
    "    return mean(tmp_data[:top_k] + [0] * (top_k - len(data)))\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Define function for generating similarity matrix between all countries from PWDB dataset"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "def generate_countries_similarity_matrix(unified_df: pd.DataFrame,\n",
    "                                         pwdb_df: pd.DataFrame,\n",
    "                                         countries: List[str]):\n",
    "    n = len(countries)\n",
    "    sim_matrix = np.zeros((n, n))\n",
    "    for i in range(0, len(countries)):\n",
    "        sim_matrix[i][i] = 0\n",
    "        df_x = prepare_df(unified_df=unified_df,\n",
    "                          pwdb_df=pwdb_df,\n",
    "                          column_filter_name='country',\n",
    "                          column_filter_value=countries[i]\n",
    "                          )\n",
    "        for j in range(i + 1, len(countries)):\n",
    "            df_y = prepare_df(unified_df=unified_df,\n",
    "                              pwdb_df=pwdb_df,\n",
    "                              column_filter_name='country',\n",
    "                              column_filter_value=countries[j]\n",
    "                              )\n",
    "            tmp_sim_matrix = cosine_similarity(df_x['emb'].values.tolist(),\n",
    "                                               df_y['emb'].values.tolist())\n",
    "            sim_mean = top_k_mean(tmp_sim_matrix[np.triu_indices_from(tmp_sim_matrix, k=1)], 5)\n",
    "            sim_matrix[i][j] = sim_matrix[j][i] = sim_mean\n",
    "        return sim_matrix"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "countries = list(unique_everseen(pwdb_df.country.values))\n",
    "countries_similarity_matrix = generate_countries_similarity_matrix(unified_df=unified_df, pwdb_df=pwdb_df,\n",
    "                                                                   countries=countries)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Create plot ( a heatmap) based on similarity matrix between countries from PWDB dataset"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "fig = px.imshow(countries_similarity_matrix,\n",
    "                labels=dict(color=\"Semantic similarity\"),\n",
    "                x=countries,\n",
    "                y=countries,\n",
    "                width=700,\n",
    "                height=700\n",
    "                )\n",
    "fig.update_xaxes(side=\"top\")\n",
    "fig.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Define function what compute similarity matrix for time periods between two countries"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "def generate_2_country_similarity_matrix(data_x: pd.DataFrame, data_y: pd.DataFrame,\n",
    "                                         start_date: str, end_date: str, periods: int):\n",
    "    data_x['Date'] = pd.to_datetime(data_x['Date']).dt.date\n",
    "    data_y['Date'] = pd.to_datetime(data_y['Date']).dt.date\n",
    "    time_periods = pd.date_range(start=start_date,\n",
    "                                 end=end_date,\n",
    "                                 periods=periods).to_pydatetime().tolist()\n",
    "    time_periods = list(map(lambda x: x.date(), time_periods))\n",
    "    time_periods = list(zip(time_periods, time_periods[1:]))\n",
    "    n = len(time_periods)\n",
    "    sim_matrix = np.zeros((n, n))\n",
    "    for i in range(0, n):\n",
    "        start_y, end_y = time_periods[i]\n",
    "        tmp_df_y = data_y[(data_y['Date'] >= start_y) & (data_y['Date'] < end_y)]\n",
    "        if len(tmp_df_y):\n",
    "            for j in range(0, n):\n",
    "                start_x, end_x = time_periods[j]\n",
    "                tmp_df_x = data_x[(data_x['Date'] >= start_x) & (data_x['Date'] < end_x)]\n",
    "                if len(tmp_df_x):\n",
    "                    tmp_sim_matrix = cosine_similarity(tmp_df_x['emb'].values.tolist(),\n",
    "                                                       tmp_df_y['emb'].values.tolist())\n",
    "                    sim_mean = top_k_mean(tmp_sim_matrix[np.triu_indices_from(tmp_sim_matrix, k=1)], 30)\n",
    "                    sim_matrix[i][j] = sim_mean\n",
    "    return sim_matrix, time_periods\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Select only first 4 countries for compute plots"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "data": {
      "text/plain": "['Croatia', 'European Union', 'Latvia', 'Hungary']"
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "countries = countries[:4]\n",
    "countries"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Draw plots for similarity between two countries distributed in time periods"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "for i in range(0, len(countries)):\n",
    "    df_x = prepare_df(unified_df=unified_df,\n",
    "                      pwdb_df=pwdb_df,\n",
    "                      column_filter_name='country',\n",
    "                      column_filter_value=countries[i]\n",
    "                      )\n",
    "    for j in range(i + 1, len(countries)):\n",
    "        df_y = prepare_df(unified_df=unified_df,\n",
    "                          pwdb_df=pwdb_df,\n",
    "                          column_filter_name='country',\n",
    "                          column_filter_value=countries[j])\n",
    "        tmp_sim_matrix, tmp_periods = generate_2_country_similarity_matrix(df_x, df_y, start_date=\"2020-01-01\",\n",
    "                                                                           end_date=\"2021-07-1\", periods=6)\n",
    "        tmp_periods = [' '.join([str(x), str(y)]) for x, y in tmp_periods]\n",
    "        color_scheme = [(0, \"orange\"),\n",
    "                        (0.5, \"yellow\"),\n",
    "                        (1, \"lime\")]\n",
    "        fig = px.imshow(tmp_sim_matrix,\n",
    "                        labels=dict(x=countries[i], y=countries[j], color=\"Semantic similarity\"),\n",
    "                        x=tmp_periods,\n",
    "                        y=tmp_periods,\n",
    "                        width=800,\n",
    "                        height=700,\n",
    "                        zmin=0,\n",
    "                        zmax=1,\n",
    "                        color_continuous_scale=color_scheme\n",
    "                        )\n",
    "        fig.update_xaxes(side=\"top\")\n",
    "        fig.update_xaxes(\n",
    "            showticklabels=True,\n",
    "            tickmode='linear',\n",
    "            tickfont=dict(\n",
    "                family='Old Standard TT, serif',\n",
    "                size=8,\n",
    "                color='black')\n",
    "        )\n",
    "        fig.update_yaxes(\n",
    "            scaleanchor=\"x\",\n",
    "            scaleratio=1,\n",
    "            showticklabels=True,\n",
    "            tickmode='linear',\n",
    "            tickfont=dict(\n",
    "                family='Old Standard TT, serif',\n",
    "                size=8,\n",
    "                color='black'\n",
    "            )\n",
    "        )\n",
    "        fig.show()\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}